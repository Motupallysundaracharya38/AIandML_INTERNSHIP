{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-nearest neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## problem statement:\n",
    "** Problem Statement **\n",
    "\n",
    "- The problem that we are going to solve here is that given a set of features that describe a tumour whether it is Malignant or Benign, our machine learning model must predict whether the tumour is Malignant or Benign. To train our machine learning model with tumour data, we will be using [SCLCData](https://raw.githubusercontent.com/Mounika-Kajjam/Datasets/master/wbcd.csv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "## importing the libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>87139402</td>\n",
       "      <td>B</td>\n",
       "      <td>12.32</td>\n",
       "      <td>12.39</td>\n",
       "      <td>78.85</td>\n",
       "      <td>464.1</td>\n",
       "      <td>0.10280</td>\n",
       "      <td>0.06981</td>\n",
       "      <td>0.03987</td>\n",
       "      <td>0.03700</td>\n",
       "      <td>...</td>\n",
       "      <td>13.50</td>\n",
       "      <td>15.64</td>\n",
       "      <td>86.97</td>\n",
       "      <td>549.1</td>\n",
       "      <td>0.1385</td>\n",
       "      <td>0.1266</td>\n",
       "      <td>0.12420</td>\n",
       "      <td>0.09391</td>\n",
       "      <td>0.2827</td>\n",
       "      <td>0.06771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8910251</td>\n",
       "      <td>B</td>\n",
       "      <td>10.60</td>\n",
       "      <td>18.95</td>\n",
       "      <td>69.28</td>\n",
       "      <td>346.4</td>\n",
       "      <td>0.09688</td>\n",
       "      <td>0.11470</td>\n",
       "      <td>0.06387</td>\n",
       "      <td>0.02642</td>\n",
       "      <td>...</td>\n",
       "      <td>11.88</td>\n",
       "      <td>22.94</td>\n",
       "      <td>78.28</td>\n",
       "      <td>424.8</td>\n",
       "      <td>0.1213</td>\n",
       "      <td>0.2515</td>\n",
       "      <td>0.19160</td>\n",
       "      <td>0.07926</td>\n",
       "      <td>0.2940</td>\n",
       "      <td>0.07587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>905520</td>\n",
       "      <td>B</td>\n",
       "      <td>11.04</td>\n",
       "      <td>16.83</td>\n",
       "      <td>70.92</td>\n",
       "      <td>373.2</td>\n",
       "      <td>0.10770</td>\n",
       "      <td>0.07804</td>\n",
       "      <td>0.03046</td>\n",
       "      <td>0.02480</td>\n",
       "      <td>...</td>\n",
       "      <td>12.41</td>\n",
       "      <td>26.44</td>\n",
       "      <td>79.93</td>\n",
       "      <td>471.4</td>\n",
       "      <td>0.1369</td>\n",
       "      <td>0.1482</td>\n",
       "      <td>0.10670</td>\n",
       "      <td>0.07431</td>\n",
       "      <td>0.2998</td>\n",
       "      <td>0.07881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>868871</td>\n",
       "      <td>B</td>\n",
       "      <td>11.28</td>\n",
       "      <td>13.39</td>\n",
       "      <td>73.00</td>\n",
       "      <td>384.8</td>\n",
       "      <td>0.11640</td>\n",
       "      <td>0.11360</td>\n",
       "      <td>0.04635</td>\n",
       "      <td>0.04796</td>\n",
       "      <td>...</td>\n",
       "      <td>11.92</td>\n",
       "      <td>15.77</td>\n",
       "      <td>76.53</td>\n",
       "      <td>434.0</td>\n",
       "      <td>0.1367</td>\n",
       "      <td>0.1822</td>\n",
       "      <td>0.08669</td>\n",
       "      <td>0.08611</td>\n",
       "      <td>0.2102</td>\n",
       "      <td>0.06784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9012568</td>\n",
       "      <td>B</td>\n",
       "      <td>15.19</td>\n",
       "      <td>13.21</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.8</td>\n",
       "      <td>0.07963</td>\n",
       "      <td>0.06934</td>\n",
       "      <td>0.03393</td>\n",
       "      <td>0.02657</td>\n",
       "      <td>...</td>\n",
       "      <td>16.20</td>\n",
       "      <td>15.73</td>\n",
       "      <td>104.50</td>\n",
       "      <td>819.1</td>\n",
       "      <td>0.1126</td>\n",
       "      <td>0.1737</td>\n",
       "      <td>0.13620</td>\n",
       "      <td>0.08178</td>\n",
       "      <td>0.2487</td>\n",
       "      <td>0.06766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0  87139402         B        12.32         12.39           78.85      464.1   \n",
       "1   8910251         B        10.60         18.95           69.28      346.4   \n",
       "2    905520         B        11.04         16.83           70.92      373.2   \n",
       "3    868871         B        11.28         13.39           73.00      384.8   \n",
       "4   9012568         B        15.19         13.21           97.65      711.8   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  points_mean  ...  \\\n",
       "0          0.10280           0.06981         0.03987      0.03700  ...   \n",
       "1          0.09688           0.11470         0.06387      0.02642  ...   \n",
       "2          0.10770           0.07804         0.03046      0.02480  ...   \n",
       "3          0.11640           0.11360         0.04635      0.04796  ...   \n",
       "4          0.07963           0.06934         0.03393      0.02657  ...   \n",
       "\n",
       "   radius_worst  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0         13.50          15.64            86.97       549.1            0.1385   \n",
       "1         11.88          22.94            78.28       424.8            0.1213   \n",
       "2         12.41          26.44            79.93       471.4            0.1369   \n",
       "3         11.92          15.77            76.53       434.0            0.1367   \n",
       "4         16.20          15.73           104.50       819.1            0.1126   \n",
       "\n",
       "   compactness_worst  concavity_worst  points_worst  symmetry_worst  \\\n",
       "0             0.1266          0.12420       0.09391          0.2827   \n",
       "1             0.2515          0.19160       0.07926          0.2940   \n",
       "2             0.1482          0.10670       0.07431          0.2998   \n",
       "3             0.1822          0.08669       0.08611          0.2102   \n",
       "4             0.1737          0.13620       0.08178          0.2487   \n",
       "\n",
       "   dimension_worst  \n",
       "0          0.06771  \n",
       "1          0.07587  \n",
       "2          0.07881  \n",
       "3          0.06784  \n",
       "4          0.06766  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"https://raw.githubusercontent.com/Mounika-Kajjam/Datasets/master/wbcd.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>3.037183e+07</td>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>...</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>1.250206e+08</td>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>...</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>8.670000e+03</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>8.692180e+05</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>...</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>9.060240e+05</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>...</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>8.813129e+06</td>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>...</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>9.113205e+08</td>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>...</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
       "count  5.690000e+02   569.000000    569.000000      569.000000   569.000000   \n",
       "mean   3.037183e+07    14.127292     19.289649       91.969033   654.889104   \n",
       "std    1.250206e+08     3.524049      4.301036       24.298981   351.914129   \n",
       "min    8.670000e+03     6.981000      9.710000       43.790000   143.500000   \n",
       "25%    8.692180e+05    11.700000     16.170000       75.170000   420.300000   \n",
       "50%    9.060240e+05    13.370000     18.840000       86.240000   551.100000   \n",
       "75%    8.813129e+06    15.780000     21.800000      104.100000   782.700000   \n",
       "max    9.113205e+08    28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       smoothness_mean  compactness_mean  concavity_mean  points_mean  \\\n",
       "count       569.000000        569.000000      569.000000   569.000000   \n",
       "mean          0.096360          0.104341        0.088799     0.048919   \n",
       "std           0.014064          0.052813        0.079720     0.038803   \n",
       "min           0.052630          0.019380        0.000000     0.000000   \n",
       "25%           0.086370          0.064920        0.029560     0.020310   \n",
       "50%           0.095870          0.092630        0.061540     0.033500   \n",
       "75%           0.105300          0.130400        0.130700     0.074000   \n",
       "max           0.163400          0.345400        0.426800     0.201200   \n",
       "\n",
       "       symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "count     569.000000  ...    569.000000     569.000000       569.000000   \n",
       "mean        0.181162  ...     16.269190      25.677223       107.261213   \n",
       "std         0.027414  ...      4.833242       6.146258        33.602542   \n",
       "min         0.106000  ...      7.930000      12.020000        50.410000   \n",
       "25%         0.161900  ...     13.010000      21.080000        84.110000   \n",
       "50%         0.179200  ...     14.970000      25.410000        97.660000   \n",
       "75%         0.195700  ...     18.790000      29.720000       125.400000   \n",
       "max         0.304000  ...     36.040000      49.540000       251.200000   \n",
       "\n",
       "        area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "count   569.000000        569.000000         569.000000       569.000000   \n",
       "mean    880.583128          0.132369           0.254265         0.272188   \n",
       "std     569.356993          0.022832           0.157336         0.208624   \n",
       "min     185.200000          0.071170           0.027290         0.000000   \n",
       "25%     515.300000          0.116600           0.147200         0.114500   \n",
       "50%     686.500000          0.131300           0.211900         0.226700   \n",
       "75%    1084.000000          0.146000           0.339100         0.382900   \n",
       "max    4254.000000          0.222600           1.058000         1.252000   \n",
       "\n",
       "       points_worst  symmetry_worst  dimension_worst  \n",
       "count    569.000000      569.000000       569.000000  \n",
       "mean       0.114606        0.290076         0.083946  \n",
       "std        0.065732        0.061867         0.018061  \n",
       "min        0.000000        0.156500         0.055040  \n",
       "25%        0.064930        0.250400         0.071460  \n",
       "50%        0.099930        0.282200         0.080040  \n",
       "75%        0.161400        0.317900         0.092080  \n",
       "max        0.291000        0.663800         0.207500  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B    357\n",
       "M    212\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.diagnosis.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                   0\n",
       "diagnosis            0\n",
       "radius_mean          0\n",
       "texture_mean         0\n",
       "perimeter_mean       0\n",
       "area_mean            0\n",
       "smoothness_mean      0\n",
       "compactness_mean     0\n",
       "concavity_mean       0\n",
       "points_mean          0\n",
       "symmetry_mean        0\n",
       "dimension_mean       0\n",
       "radius_se            0\n",
       "texture_se           0\n",
       "perimeter_se         0\n",
       "area_se              0\n",
       "smoothness_se        0\n",
       "compactness_se       0\n",
       "concavity_se         0\n",
       "points_se            0\n",
       "symmetry_se          0\n",
       "dimension_se         0\n",
       "radius_worst         0\n",
       "texture_worst        0\n",
       "perimeter_worst      0\n",
       "area_worst           0\n",
       "smoothness_worst     0\n",
       "compactness_worst    0\n",
       "concavity_worst      0\n",
       "points_worst         0\n",
       "symmetry_worst       0\n",
       "dimension_worst      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset input and the output---->train and test \n",
    "# train --> building the model \n",
    "# test -->how well the model has learnt(genralize on unseen data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>12.32</td>\n",
       "      <td>12.39</td>\n",
       "      <td>78.85</td>\n",
       "      <td>464.1</td>\n",
       "      <td>0.10280</td>\n",
       "      <td>0.06981</td>\n",
       "      <td>0.03987</td>\n",
       "      <td>0.03700</td>\n",
       "      <td>0.1959</td>\n",
       "      <td>0.05955</td>\n",
       "      <td>...</td>\n",
       "      <td>13.50</td>\n",
       "      <td>15.64</td>\n",
       "      <td>86.97</td>\n",
       "      <td>549.1</td>\n",
       "      <td>0.1385</td>\n",
       "      <td>0.1266</td>\n",
       "      <td>0.12420</td>\n",
       "      <td>0.09391</td>\n",
       "      <td>0.2827</td>\n",
       "      <td>0.06771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10.60</td>\n",
       "      <td>18.95</td>\n",
       "      <td>69.28</td>\n",
       "      <td>346.4</td>\n",
       "      <td>0.09688</td>\n",
       "      <td>0.11470</td>\n",
       "      <td>0.06387</td>\n",
       "      <td>0.02642</td>\n",
       "      <td>0.1922</td>\n",
       "      <td>0.06491</td>\n",
       "      <td>...</td>\n",
       "      <td>11.88</td>\n",
       "      <td>22.94</td>\n",
       "      <td>78.28</td>\n",
       "      <td>424.8</td>\n",
       "      <td>0.1213</td>\n",
       "      <td>0.2515</td>\n",
       "      <td>0.19160</td>\n",
       "      <td>0.07926</td>\n",
       "      <td>0.2940</td>\n",
       "      <td>0.07587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>11.04</td>\n",
       "      <td>16.83</td>\n",
       "      <td>70.92</td>\n",
       "      <td>373.2</td>\n",
       "      <td>0.10770</td>\n",
       "      <td>0.07804</td>\n",
       "      <td>0.03046</td>\n",
       "      <td>0.02480</td>\n",
       "      <td>0.1714</td>\n",
       "      <td>0.06340</td>\n",
       "      <td>...</td>\n",
       "      <td>12.41</td>\n",
       "      <td>26.44</td>\n",
       "      <td>79.93</td>\n",
       "      <td>471.4</td>\n",
       "      <td>0.1369</td>\n",
       "      <td>0.1482</td>\n",
       "      <td>0.10670</td>\n",
       "      <td>0.07431</td>\n",
       "      <td>0.2998</td>\n",
       "      <td>0.07881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11.28</td>\n",
       "      <td>13.39</td>\n",
       "      <td>73.00</td>\n",
       "      <td>384.8</td>\n",
       "      <td>0.11640</td>\n",
       "      <td>0.11360</td>\n",
       "      <td>0.04635</td>\n",
       "      <td>0.04796</td>\n",
       "      <td>0.1771</td>\n",
       "      <td>0.06072</td>\n",
       "      <td>...</td>\n",
       "      <td>11.92</td>\n",
       "      <td>15.77</td>\n",
       "      <td>76.53</td>\n",
       "      <td>434.0</td>\n",
       "      <td>0.1367</td>\n",
       "      <td>0.1822</td>\n",
       "      <td>0.08669</td>\n",
       "      <td>0.08611</td>\n",
       "      <td>0.2102</td>\n",
       "      <td>0.06784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>15.19</td>\n",
       "      <td>13.21</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.8</td>\n",
       "      <td>0.07963</td>\n",
       "      <td>0.06934</td>\n",
       "      <td>0.03393</td>\n",
       "      <td>0.02657</td>\n",
       "      <td>0.1721</td>\n",
       "      <td>0.05544</td>\n",
       "      <td>...</td>\n",
       "      <td>16.20</td>\n",
       "      <td>15.73</td>\n",
       "      <td>104.50</td>\n",
       "      <td>819.1</td>\n",
       "      <td>0.1126</td>\n",
       "      <td>0.1737</td>\n",
       "      <td>0.13620</td>\n",
       "      <td>0.08178</td>\n",
       "      <td>0.2487</td>\n",
       "      <td>0.06766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0        12.32         12.39           78.85      464.1          0.10280   \n",
       "1        10.60         18.95           69.28      346.4          0.09688   \n",
       "2        11.04         16.83           70.92      373.2          0.10770   \n",
       "3        11.28         13.39           73.00      384.8          0.11640   \n",
       "4        15.19         13.21           97.65      711.8          0.07963   \n",
       "\n",
       "   compactness_mean  concavity_mean  points_mean  symmetry_mean  \\\n",
       "0           0.06981         0.03987      0.03700         0.1959   \n",
       "1           0.11470         0.06387      0.02642         0.1922   \n",
       "2           0.07804         0.03046      0.02480         0.1714   \n",
       "3           0.11360         0.04635      0.04796         0.1771   \n",
       "4           0.06934         0.03393      0.02657         0.1721   \n",
       "\n",
       "   dimension_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.05955  ...         13.50          15.64            86.97   \n",
       "1         0.06491  ...         11.88          22.94            78.28   \n",
       "2         0.06340  ...         12.41          26.44            79.93   \n",
       "3         0.06072  ...         11.92          15.77            76.53   \n",
       "4         0.05544  ...         16.20          15.73           104.50   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0       549.1            0.1385             0.1266          0.12420   \n",
       "1       424.8            0.1213             0.2515          0.19160   \n",
       "2       471.4            0.1369             0.1482          0.10670   \n",
       "3       434.0            0.1367             0.1822          0.08669   \n",
       "4       819.1            0.1126             0.1737          0.13620   \n",
       "\n",
       "   points_worst  symmetry_worst  dimension_worst  \n",
       "0       0.09391          0.2827          0.06771  \n",
       "1       0.07926          0.2940          0.07587  \n",
       "2       0.07431          0.2998          0.07881  \n",
       "3       0.08611          0.2102          0.06784  \n",
       "4       0.08178          0.2487          0.06766  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## preparing input and output \n",
    "## drop the id and diagnosis columns\n",
    "X=data.drop(['id','diagnosis'],axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    B\n",
       "1    B\n",
       "2    B\n",
       "3    B\n",
       "4    B\n",
       "Name: diagnosis, dtype: object"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## acessing output column \n",
    "y=data.diagnosis\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing training and testing data\n",
    "# starting 70% of the data (569 rows) into training anfd remainin g 30& of the data into testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.30,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(398, 30)\n",
      "(171, 30)\n",
      "(398,)\n",
      "(171,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>14.34</td>\n",
       "      <td>13.47</td>\n",
       "      <td>92.51</td>\n",
       "      <td>641.2</td>\n",
       "      <td>0.09906</td>\n",
       "      <td>0.07624</td>\n",
       "      <td>0.05724</td>\n",
       "      <td>0.046030</td>\n",
       "      <td>0.2075</td>\n",
       "      <td>0.05448</td>\n",
       "      <td>...</td>\n",
       "      <td>16.77</td>\n",
       "      <td>16.90</td>\n",
       "      <td>110.40</td>\n",
       "      <td>873.2</td>\n",
       "      <td>0.1297</td>\n",
       "      <td>0.15250</td>\n",
       "      <td>0.16320</td>\n",
       "      <td>0.10870</td>\n",
       "      <td>0.3062</td>\n",
       "      <td>0.06072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>384</td>\n",
       "      <td>11.34</td>\n",
       "      <td>18.61</td>\n",
       "      <td>72.76</td>\n",
       "      <td>391.2</td>\n",
       "      <td>0.10490</td>\n",
       "      <td>0.08499</td>\n",
       "      <td>0.04302</td>\n",
       "      <td>0.025940</td>\n",
       "      <td>0.1927</td>\n",
       "      <td>0.06211</td>\n",
       "      <td>...</td>\n",
       "      <td>12.47</td>\n",
       "      <td>23.03</td>\n",
       "      <td>79.15</td>\n",
       "      <td>478.6</td>\n",
       "      <td>0.1483</td>\n",
       "      <td>0.15740</td>\n",
       "      <td>0.16240</td>\n",
       "      <td>0.08542</td>\n",
       "      <td>0.3060</td>\n",
       "      <td>0.06783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>558</td>\n",
       "      <td>11.08</td>\n",
       "      <td>14.71</td>\n",
       "      <td>70.21</td>\n",
       "      <td>372.7</td>\n",
       "      <td>0.10060</td>\n",
       "      <td>0.05743</td>\n",
       "      <td>0.02363</td>\n",
       "      <td>0.025830</td>\n",
       "      <td>0.1566</td>\n",
       "      <td>0.06669</td>\n",
       "      <td>...</td>\n",
       "      <td>11.35</td>\n",
       "      <td>16.82</td>\n",
       "      <td>72.01</td>\n",
       "      <td>396.5</td>\n",
       "      <td>0.1216</td>\n",
       "      <td>0.08240</td>\n",
       "      <td>0.03938</td>\n",
       "      <td>0.04306</td>\n",
       "      <td>0.1902</td>\n",
       "      <td>0.07313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>451</td>\n",
       "      <td>12.34</td>\n",
       "      <td>26.86</td>\n",
       "      <td>81.15</td>\n",
       "      <td>477.4</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.13530</td>\n",
       "      <td>0.10850</td>\n",
       "      <td>0.045620</td>\n",
       "      <td>0.1943</td>\n",
       "      <td>0.06937</td>\n",
       "      <td>...</td>\n",
       "      <td>15.65</td>\n",
       "      <td>39.34</td>\n",
       "      <td>101.70</td>\n",
       "      <td>768.9</td>\n",
       "      <td>0.1785</td>\n",
       "      <td>0.47060</td>\n",
       "      <td>0.44250</td>\n",
       "      <td>0.14590</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.12050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>333</td>\n",
       "      <td>12.18</td>\n",
       "      <td>14.08</td>\n",
       "      <td>77.25</td>\n",
       "      <td>461.4</td>\n",
       "      <td>0.07734</td>\n",
       "      <td>0.03212</td>\n",
       "      <td>0.01123</td>\n",
       "      <td>0.005051</td>\n",
       "      <td>0.1673</td>\n",
       "      <td>0.05649</td>\n",
       "      <td>...</td>\n",
       "      <td>12.85</td>\n",
       "      <td>16.47</td>\n",
       "      <td>81.60</td>\n",
       "      <td>513.1</td>\n",
       "      <td>0.1001</td>\n",
       "      <td>0.05332</td>\n",
       "      <td>0.04116</td>\n",
       "      <td>0.01852</td>\n",
       "      <td>0.2293</td>\n",
       "      <td>0.06037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>299</td>\n",
       "      <td>16.25</td>\n",
       "      <td>19.51</td>\n",
       "      <td>109.80</td>\n",
       "      <td>815.8</td>\n",
       "      <td>0.10260</td>\n",
       "      <td>0.18930</td>\n",
       "      <td>0.22360</td>\n",
       "      <td>0.091940</td>\n",
       "      <td>0.2151</td>\n",
       "      <td>0.06578</td>\n",
       "      <td>...</td>\n",
       "      <td>17.39</td>\n",
       "      <td>23.05</td>\n",
       "      <td>122.10</td>\n",
       "      <td>939.7</td>\n",
       "      <td>0.1377</td>\n",
       "      <td>0.44620</td>\n",
       "      <td>0.58970</td>\n",
       "      <td>0.17750</td>\n",
       "      <td>0.3318</td>\n",
       "      <td>0.09136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>534</td>\n",
       "      <td>19.79</td>\n",
       "      <td>25.12</td>\n",
       "      <td>130.40</td>\n",
       "      <td>1192.0</td>\n",
       "      <td>0.10150</td>\n",
       "      <td>0.15890</td>\n",
       "      <td>0.25450</td>\n",
       "      <td>0.114900</td>\n",
       "      <td>0.2202</td>\n",
       "      <td>0.06113</td>\n",
       "      <td>...</td>\n",
       "      <td>22.63</td>\n",
       "      <td>33.58</td>\n",
       "      <td>148.70</td>\n",
       "      <td>1589.0</td>\n",
       "      <td>0.1275</td>\n",
       "      <td>0.38610</td>\n",
       "      <td>0.56730</td>\n",
       "      <td>0.17320</td>\n",
       "      <td>0.3305</td>\n",
       "      <td>0.08465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>493</td>\n",
       "      <td>10.96</td>\n",
       "      <td>17.62</td>\n",
       "      <td>70.79</td>\n",
       "      <td>365.6</td>\n",
       "      <td>0.09687</td>\n",
       "      <td>0.09752</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.027880</td>\n",
       "      <td>0.1619</td>\n",
       "      <td>0.06408</td>\n",
       "      <td>...</td>\n",
       "      <td>11.62</td>\n",
       "      <td>26.51</td>\n",
       "      <td>76.43</td>\n",
       "      <td>407.5</td>\n",
       "      <td>0.1428</td>\n",
       "      <td>0.25100</td>\n",
       "      <td>0.21230</td>\n",
       "      <td>0.09861</td>\n",
       "      <td>0.2289</td>\n",
       "      <td>0.08278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>527</td>\n",
       "      <td>17.95</td>\n",
       "      <td>20.01</td>\n",
       "      <td>114.20</td>\n",
       "      <td>982.0</td>\n",
       "      <td>0.08402</td>\n",
       "      <td>0.06722</td>\n",
       "      <td>0.07293</td>\n",
       "      <td>0.055960</td>\n",
       "      <td>0.2129</td>\n",
       "      <td>0.05025</td>\n",
       "      <td>...</td>\n",
       "      <td>20.58</td>\n",
       "      <td>27.83</td>\n",
       "      <td>129.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.1072</td>\n",
       "      <td>0.12020</td>\n",
       "      <td>0.22490</td>\n",
       "      <td>0.11850</td>\n",
       "      <td>0.4882</td>\n",
       "      <td>0.06111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>13.15</td>\n",
       "      <td>15.34</td>\n",
       "      <td>85.31</td>\n",
       "      <td>538.9</td>\n",
       "      <td>0.09384</td>\n",
       "      <td>0.08498</td>\n",
       "      <td>0.09293</td>\n",
       "      <td>0.034830</td>\n",
       "      <td>0.1822</td>\n",
       "      <td>0.06207</td>\n",
       "      <td>...</td>\n",
       "      <td>14.77</td>\n",
       "      <td>20.50</td>\n",
       "      <td>97.67</td>\n",
       "      <td>677.3</td>\n",
       "      <td>0.1478</td>\n",
       "      <td>0.22560</td>\n",
       "      <td>0.30090</td>\n",
       "      <td>0.09722</td>\n",
       "      <td>0.3849</td>\n",
       "      <td>0.08633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>398 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "166        14.34         13.47           92.51      641.2          0.09906   \n",
       "384        11.34         18.61           72.76      391.2          0.10490   \n",
       "558        11.08         14.71           70.21      372.7          0.10060   \n",
       "451        12.34         26.86           81.15      477.4          0.10340   \n",
       "333        12.18         14.08           77.25      461.4          0.07734   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "299        16.25         19.51          109.80      815.8          0.10260   \n",
       "534        19.79         25.12          130.40     1192.0          0.10150   \n",
       "493        10.96         17.62           70.79      365.6          0.09687   \n",
       "527        17.95         20.01          114.20      982.0          0.08402   \n",
       "168        13.15         15.34           85.31      538.9          0.09384   \n",
       "\n",
       "     compactness_mean  concavity_mean  points_mean  symmetry_mean  \\\n",
       "166           0.07624         0.05724     0.046030         0.2075   \n",
       "384           0.08499         0.04302     0.025940         0.1927   \n",
       "558           0.05743         0.02363     0.025830         0.1566   \n",
       "451           0.13530         0.10850     0.045620         0.1943   \n",
       "333           0.03212         0.01123     0.005051         0.1673   \n",
       "..                ...             ...          ...            ...   \n",
       "299           0.18930         0.22360     0.091940         0.2151   \n",
       "534           0.15890         0.25450     0.114900         0.2202   \n",
       "493           0.09752         0.05263     0.027880         0.1619   \n",
       "527           0.06722         0.07293     0.055960         0.2129   \n",
       "168           0.08498         0.09293     0.034830         0.1822   \n",
       "\n",
       "     dimension_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "166         0.05448  ...         16.77          16.90           110.40   \n",
       "384         0.06211  ...         12.47          23.03            79.15   \n",
       "558         0.06669  ...         11.35          16.82            72.01   \n",
       "451         0.06937  ...         15.65          39.34           101.70   \n",
       "333         0.05649  ...         12.85          16.47            81.60   \n",
       "..              ...  ...           ...            ...              ...   \n",
       "299         0.06578  ...         17.39          23.05           122.10   \n",
       "534         0.06113  ...         22.63          33.58           148.70   \n",
       "493         0.06408  ...         11.62          26.51            76.43   \n",
       "527         0.05025  ...         20.58          27.83           129.20   \n",
       "168         0.06207  ...         14.77          20.50            97.67   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "166       873.2            0.1297            0.15250          0.16320   \n",
       "384       478.6            0.1483            0.15740          0.16240   \n",
       "558       396.5            0.1216            0.08240          0.03938   \n",
       "451       768.9            0.1785            0.47060          0.44250   \n",
       "333       513.1            0.1001            0.05332          0.04116   \n",
       "..          ...               ...                ...              ...   \n",
       "299       939.7            0.1377            0.44620          0.58970   \n",
       "534      1589.0            0.1275            0.38610          0.56730   \n",
       "493       407.5            0.1428            0.25100          0.21230   \n",
       "527      1261.0            0.1072            0.12020          0.22490   \n",
       "168       677.3            0.1478            0.22560          0.30090   \n",
       "\n",
       "     points_worst  symmetry_worst  dimension_worst  \n",
       "166       0.10870          0.3062          0.06072  \n",
       "384       0.08542          0.3060          0.06783  \n",
       "558       0.04306          0.1902          0.07313  \n",
       "451       0.14590          0.3215          0.12050  \n",
       "333       0.01852          0.2293          0.06037  \n",
       "..            ...             ...              ...  \n",
       "299       0.17750          0.3318          0.09136  \n",
       "534       0.17320          0.3305          0.08465  \n",
       "493       0.09861          0.2289          0.08278  \n",
       "527       0.11850          0.4882          0.06111  \n",
       "168       0.09722          0.3849          0.08633  \n",
       "\n",
       "[398 rows x 30 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before spliting if you apply standardization ---> you are considering whole\n",
    "# you are including test data also into training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0654828 , -1.35518629,  0.03134589, ..., -0.04689041,\n",
       "         0.3683001 , -1.22806684],\n",
       "       [-0.77639967, -0.1225787 , -0.77192193, ..., -0.39868555,\n",
       "         0.3648074 , -0.83648993],\n",
       "       [-0.84936282, -1.05782571, -0.87563499, ..., -1.03880764,\n",
       "        -1.65746674, -0.54459715],\n",
       "       ...,\n",
       "       [-0.88303812, -0.35998755, -0.85204535, ..., -0.1993652 ,\n",
       "        -0.98162901, -0.01313199],\n",
       "       [ 1.07854805,  0.213151  ,  0.91351698, ...,  0.10120204,\n",
       "         3.54665843, -1.20658794],\n",
       "       [-0.26846391, -0.90674734, -0.26149099, ..., -0.22037015,\n",
       "         1.74267813,  0.1823811 ]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_X_train = scaler.fit_transform(X_train)\n",
    "scaled_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array values ,we have created  data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.065483</td>\n",
       "      <td>-1.355186</td>\n",
       "      <td>0.031346</td>\n",
       "      <td>-0.035592</td>\n",
       "      <td>0.240960</td>\n",
       "      <td>-0.482979</td>\n",
       "      <td>-0.357708</td>\n",
       "      <td>-0.046272</td>\n",
       "      <td>1.043490</td>\n",
       "      <td>-1.165341</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125178</td>\n",
       "      <td>-1.425939</td>\n",
       "      <td>0.117536</td>\n",
       "      <td>0.004168</td>\n",
       "      <td>-0.067496</td>\n",
       "      <td>-0.603330</td>\n",
       "      <td>-0.480560</td>\n",
       "      <td>-0.046890</td>\n",
       "      <td>0.368300</td>\n",
       "      <td>-1.228067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.776400</td>\n",
       "      <td>-0.122579</td>\n",
       "      <td>-0.771922</td>\n",
       "      <td>-0.735368</td>\n",
       "      <td>0.647407</td>\n",
       "      <td>-0.311306</td>\n",
       "      <td>-0.538400</td>\n",
       "      <td>-0.554964</td>\n",
       "      <td>0.487938</td>\n",
       "      <td>-0.040111</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.762720</td>\n",
       "      <td>-0.388938</td>\n",
       "      <td>-0.811034</td>\n",
       "      <td>-0.683149</td>\n",
       "      <td>0.750316</td>\n",
       "      <td>-0.570666</td>\n",
       "      <td>-0.484590</td>\n",
       "      <td>-0.398686</td>\n",
       "      <td>0.364807</td>\n",
       "      <td>-0.836490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.849363</td>\n",
       "      <td>-1.057826</td>\n",
       "      <td>-0.875635</td>\n",
       "      <td>-0.787151</td>\n",
       "      <td>0.348139</td>\n",
       "      <td>-0.852027</td>\n",
       "      <td>-0.784787</td>\n",
       "      <td>-0.557750</td>\n",
       "      <td>-0.867159</td>\n",
       "      <td>0.635322</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.993986</td>\n",
       "      <td>-1.439473</td>\n",
       "      <td>-1.023193</td>\n",
       "      <td>-0.826151</td>\n",
       "      <td>-0.423640</td>\n",
       "      <td>-1.070632</td>\n",
       "      <td>-1.104405</td>\n",
       "      <td>-1.038808</td>\n",
       "      <td>-1.657467</td>\n",
       "      <td>-0.544597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.495772</td>\n",
       "      <td>1.855828</td>\n",
       "      <td>-0.430686</td>\n",
       "      <td>-0.494085</td>\n",
       "      <td>0.543011</td>\n",
       "      <td>0.675764</td>\n",
       "      <td>0.293648</td>\n",
       "      <td>-0.056654</td>\n",
       "      <td>0.547997</td>\n",
       "      <td>1.030554</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.106089</td>\n",
       "      <td>2.370196</td>\n",
       "      <td>-0.140978</td>\n",
       "      <td>-0.177502</td>\n",
       "      <td>2.078160</td>\n",
       "      <td>1.517193</td>\n",
       "      <td>0.926643</td>\n",
       "      <td>0.515256</td>\n",
       "      <td>0.635492</td>\n",
       "      <td>2.064263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.540673</td>\n",
       "      <td>-1.208904</td>\n",
       "      <td>-0.589306</td>\n",
       "      <td>-0.538871</td>\n",
       "      <td>-1.270688</td>\n",
       "      <td>-1.348603</td>\n",
       "      <td>-0.942352</td>\n",
       "      <td>-1.083888</td>\n",
       "      <td>-0.465510</td>\n",
       "      <td>-0.868918</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.684254</td>\n",
       "      <td>-1.498682</td>\n",
       "      <td>-0.738234</td>\n",
       "      <td>-0.623056</td>\n",
       "      <td>-1.368960</td>\n",
       "      <td>-1.264486</td>\n",
       "      <td>-1.095436</td>\n",
       "      <td>-1.409643</td>\n",
       "      <td>-0.974644</td>\n",
       "      <td>-1.247343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>393</td>\n",
       "      <td>0.601481</td>\n",
       "      <td>0.093248</td>\n",
       "      <td>0.734561</td>\n",
       "      <td>0.453131</td>\n",
       "      <td>0.487333</td>\n",
       "      <td>1.735231</td>\n",
       "      <td>1.756211</td>\n",
       "      <td>1.116199</td>\n",
       "      <td>1.328773</td>\n",
       "      <td>0.501121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.253200</td>\n",
       "      <td>-0.385555</td>\n",
       "      <td>0.465193</td>\n",
       "      <td>0.119998</td>\n",
       "      <td>0.284251</td>\n",
       "      <td>1.354538</td>\n",
       "      <td>1.668284</td>\n",
       "      <td>0.992779</td>\n",
       "      <td>0.815366</td>\n",
       "      <td>0.459404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>394</td>\n",
       "      <td>1.594903</td>\n",
       "      <td>1.438564</td>\n",
       "      <td>1.572400</td>\n",
       "      <td>1.506153</td>\n",
       "      <td>0.410777</td>\n",
       "      <td>1.138790</td>\n",
       "      <td>2.148854</td>\n",
       "      <td>1.697561</td>\n",
       "      <td>1.520214</td>\n",
       "      <td>-0.184636</td>\n",
       "      <td>...</td>\n",
       "      <td>1.335196</td>\n",
       "      <td>1.395787</td>\n",
       "      <td>1.255592</td>\n",
       "      <td>1.250953</td>\n",
       "      <td>-0.164226</td>\n",
       "      <td>0.953898</td>\n",
       "      <td>1.555425</td>\n",
       "      <td>0.927800</td>\n",
       "      <td>0.792663</td>\n",
       "      <td>0.089857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>-0.883038</td>\n",
       "      <td>-0.359988</td>\n",
       "      <td>-0.852045</td>\n",
       "      <td>-0.807025</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>-0.065471</td>\n",
       "      <td>-0.416287</td>\n",
       "      <td>-0.505842</td>\n",
       "      <td>-0.668211</td>\n",
       "      <td>0.250414</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.938234</td>\n",
       "      <td>0.199767</td>\n",
       "      <td>-0.891856</td>\n",
       "      <td>-0.806991</td>\n",
       "      <td>0.508490</td>\n",
       "      <td>0.053292</td>\n",
       "      <td>-0.233178</td>\n",
       "      <td>-0.199365</td>\n",
       "      <td>-0.981629</td>\n",
       "      <td>-0.013132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>1.078548</td>\n",
       "      <td>0.213151</td>\n",
       "      <td>0.913517</td>\n",
       "      <td>0.918342</td>\n",
       "      <td>-0.805780</td>\n",
       "      <td>-0.659950</td>\n",
       "      <td>-0.158337</td>\n",
       "      <td>0.205162</td>\n",
       "      <td>1.246191</td>\n",
       "      <td>-1.789158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.911896</td>\n",
       "      <td>0.423069</td>\n",
       "      <td>0.676164</td>\n",
       "      <td>0.679640</td>\n",
       "      <td>-1.056784</td>\n",
       "      <td>-0.818649</td>\n",
       "      <td>-0.169695</td>\n",
       "      <td>0.101202</td>\n",
       "      <td>3.546658</td>\n",
       "      <td>-1.206588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>-0.268464</td>\n",
       "      <td>-0.906747</td>\n",
       "      <td>-0.261491</td>\n",
       "      <td>-0.321940</td>\n",
       "      <td>-0.122337</td>\n",
       "      <td>-0.311503</td>\n",
       "      <td>0.095801</td>\n",
       "      <td>-0.329864</td>\n",
       "      <td>0.093796</td>\n",
       "      <td>-0.046010</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.287798</td>\n",
       "      <td>-0.816934</td>\n",
       "      <td>-0.260726</td>\n",
       "      <td>-0.337052</td>\n",
       "      <td>0.728332</td>\n",
       "      <td>-0.116030</td>\n",
       "      <td>0.213217</td>\n",
       "      <td>-0.220370</td>\n",
       "      <td>1.742678</td>\n",
       "      <td>0.182381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>398 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0       0.065483     -1.355186        0.031346  -0.035592         0.240960   \n",
       "1      -0.776400     -0.122579       -0.771922  -0.735368         0.647407   \n",
       "2      -0.849363     -1.057826       -0.875635  -0.787151         0.348139   \n",
       "3      -0.495772      1.855828       -0.430686  -0.494085         0.543011   \n",
       "4      -0.540673     -1.208904       -0.589306  -0.538871        -1.270688   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "393     0.601481      0.093248        0.734561   0.453131         0.487333   \n",
       "394     1.594903      1.438564        1.572400   1.506153         0.410777   \n",
       "395    -0.883038     -0.359988       -0.852045  -0.807025         0.088542   \n",
       "396     1.078548      0.213151        0.913517   0.918342        -0.805780   \n",
       "397    -0.268464     -0.906747       -0.261491  -0.321940        -0.122337   \n",
       "\n",
       "     compactness_mean  concavity_mean  points_mean  symmetry_mean  \\\n",
       "0           -0.482979       -0.357708    -0.046272       1.043490   \n",
       "1           -0.311306       -0.538400    -0.554964       0.487938   \n",
       "2           -0.852027       -0.784787    -0.557750      -0.867159   \n",
       "3            0.675764        0.293648    -0.056654       0.547997   \n",
       "4           -1.348603       -0.942352    -1.083888      -0.465510   \n",
       "..                ...             ...          ...            ...   \n",
       "393          1.735231        1.756211     1.116199       1.328773   \n",
       "394          1.138790        2.148854     1.697561       1.520214   \n",
       "395         -0.065471       -0.416287    -0.505842      -0.668211   \n",
       "396         -0.659950       -0.158337     0.205162       1.246191   \n",
       "397         -0.311503        0.095801    -0.329864       0.093796   \n",
       "\n",
       "     dimension_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         -1.165341  ...      0.125178      -1.425939         0.117536   \n",
       "1         -0.040111  ...     -0.762720      -0.388938        -0.811034   \n",
       "2          0.635322  ...     -0.993986      -1.439473        -1.023193   \n",
       "3          1.030554  ...     -0.106089       2.370196        -0.140978   \n",
       "4         -0.868918  ...     -0.684254      -1.498682        -0.738234   \n",
       "..              ...  ...           ...            ...              ...   \n",
       "393        0.501121  ...      0.253200      -0.385555         0.465193   \n",
       "394       -0.184636  ...      1.335196       1.395787         1.255592   \n",
       "395        0.250414  ...     -0.938234       0.199767        -0.891856   \n",
       "396       -1.789158  ...      0.911896       0.423069         0.676164   \n",
       "397       -0.046010  ...     -0.287798      -0.816934        -0.260726   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      0.004168         -0.067496          -0.603330        -0.480560   \n",
       "1     -0.683149          0.750316          -0.570666        -0.484590   \n",
       "2     -0.826151         -0.423640          -1.070632        -1.104405   \n",
       "3     -0.177502          2.078160           1.517193         0.926643   \n",
       "4     -0.623056         -1.368960          -1.264486        -1.095436   \n",
       "..          ...               ...                ...              ...   \n",
       "393    0.119998          0.284251           1.354538         1.668284   \n",
       "394    1.250953         -0.164226           0.953898         1.555425   \n",
       "395   -0.806991          0.508490           0.053292        -0.233178   \n",
       "396    0.679640         -1.056784          -0.818649        -0.169695   \n",
       "397   -0.337052          0.728332          -0.116030         0.213217   \n",
       "\n",
       "     points_worst  symmetry_worst  dimension_worst  \n",
       "0       -0.046890        0.368300        -1.228067  \n",
       "1       -0.398686        0.364807        -0.836490  \n",
       "2       -1.038808       -1.657467        -0.544597  \n",
       "3        0.515256        0.635492         2.064263  \n",
       "4       -1.409643       -0.974644        -1.247343  \n",
       "..            ...             ...              ...  \n",
       "393      0.992779        0.815366         0.459404  \n",
       "394      0.927800        0.792663         0.089857  \n",
       "395     -0.199365       -0.981629        -0.013132  \n",
       "396      0.101202        3.546658        -1.206588  \n",
       "397     -0.220370        1.742678         0.182381  \n",
       "\n",
       "[398 rows x 30 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scaling Data \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# Scaling for the training data\n",
    "scaled_X_train = pd.DataFrame(scaler.fit_transform(X_train),columns=X_train.columns)\n",
    "scaled_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.820383</td>\n",
       "      <td>-0.173809</td>\n",
       "      <td>-0.864054</td>\n",
       "      <td>-0.772484</td>\n",
       "      <td>-0.839113</td>\n",
       "      <td>-1.115846</td>\n",
       "      <td>-0.895059</td>\n",
       "      <td>-0.803603</td>\n",
       "      <td>0.581700</td>\n",
       "      <td>-0.557191</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.867791</td>\n",
       "      <td>-0.052852</td>\n",
       "      <td>-0.896889</td>\n",
       "      <td>-0.798979</td>\n",
       "      <td>-1.019902</td>\n",
       "      <td>-1.079349</td>\n",
       "      <td>-1.007702</td>\n",
       "      <td>-0.923140</td>\n",
       "      <td>0.358435</td>\n",
       "      <td>-0.918749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.141927</td>\n",
       "      <td>-0.792820</td>\n",
       "      <td>-0.198179</td>\n",
       "      <td>-0.230883</td>\n",
       "      <td>-1.152495</td>\n",
       "      <td>-0.871458</td>\n",
       "      <td>-0.875741</td>\n",
       "      <td>-0.842076</td>\n",
       "      <td>0.091697</td>\n",
       "      <td>-0.935263</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.349774</td>\n",
       "      <td>-0.954952</td>\n",
       "      <td>-0.300309</td>\n",
       "      <td>-0.418776</td>\n",
       "      <td>-1.077035</td>\n",
       "      <td>-0.417112</td>\n",
       "      <td>-0.746220</td>\n",
       "      <td>-0.800681</td>\n",
       "      <td>0.438508</td>\n",
       "      <td>-0.516902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.127255</td>\n",
       "      <td>-0.621604</td>\n",
       "      <td>1.062181</td>\n",
       "      <td>0.984540</td>\n",
       "      <td>-0.660692</td>\n",
       "      <td>0.192327</td>\n",
       "      <td>0.150940</td>\n",
       "      <td>0.302088</td>\n",
       "      <td>-0.436534</td>\n",
       "      <td>-0.788529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.807410</td>\n",
       "      <td>-0.679606</td>\n",
       "      <td>0.724717</td>\n",
       "      <td>0.699342</td>\n",
       "      <td>-0.382650</td>\n",
       "      <td>-0.081638</td>\n",
       "      <td>0.551709</td>\n",
       "      <td>0.505600</td>\n",
       "      <td>-0.249256</td>\n",
       "      <td>-0.219070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.981224</td>\n",
       "      <td>0.993971</td>\n",
       "      <td>-1.003433</td>\n",
       "      <td>-0.874237</td>\n",
       "      <td>-1.236369</td>\n",
       "      <td>-0.830667</td>\n",
       "      <td>-0.999770</td>\n",
       "      <td>-1.171264</td>\n",
       "      <td>0.453118</td>\n",
       "      <td>-0.064110</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.727843</td>\n",
       "      <td>0.754930</td>\n",
       "      <td>-0.758478</td>\n",
       "      <td>-0.715669</td>\n",
       "      <td>-0.641946</td>\n",
       "      <td>-0.689611</td>\n",
       "      <td>-1.066559</td>\n",
       "      <td>-1.382204</td>\n",
       "      <td>0.061024</td>\n",
       "      <td>-0.559531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.574547</td>\n",
       "      <td>-1.058424</td>\n",
       "      <td>0.501265</td>\n",
       "      <td>0.422529</td>\n",
       "      <td>-0.242850</td>\n",
       "      <td>-0.490922</td>\n",
       "      <td>-0.513499</td>\n",
       "      <td>-0.165548</td>\n",
       "      <td>-0.384406</td>\n",
       "      <td>-0.662945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.249706</td>\n",
       "      <td>-1.050791</td>\n",
       "      <td>0.202296</td>\n",
       "      <td>0.080185</td>\n",
       "      <td>-0.633156</td>\n",
       "      <td>-0.637230</td>\n",
       "      <td>-0.321219</td>\n",
       "      <td>-0.128562</td>\n",
       "      <td>-0.340767</td>\n",
       "      <td>-0.908518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>-0.916888</td>\n",
       "      <td>-0.625994</td>\n",
       "      <td>-0.917171</td>\n",
       "      <td>-0.839925</td>\n",
       "      <td>0.729320</td>\n",
       "      <td>-0.615620</td>\n",
       "      <td>-0.815449</td>\n",
       "      <td>-0.720426</td>\n",
       "      <td>-0.457386</td>\n",
       "      <td>-0.048247</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.857347</td>\n",
       "      <td>-0.007215</td>\n",
       "      <td>-0.877674</td>\n",
       "      <td>-0.777207</td>\n",
       "      <td>0.083204</td>\n",
       "      <td>-0.778482</td>\n",
       "      <td>-0.869224</td>\n",
       "      <td>-0.731329</td>\n",
       "      <td>-0.026197</td>\n",
       "      <td>-0.414593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167</td>\n",
       "      <td>-0.109758</td>\n",
       "      <td>-0.854282</td>\n",
       "      <td>-0.088121</td>\n",
       "      <td>-0.216093</td>\n",
       "      <td>0.195580</td>\n",
       "      <td>0.278202</td>\n",
       "      <td>-0.231850</td>\n",
       "      <td>-0.018971</td>\n",
       "      <td>-0.638096</td>\n",
       "      <td>0.250510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011585</td>\n",
       "      <td>-0.856071</td>\n",
       "      <td>0.034161</td>\n",
       "      <td>-0.163628</td>\n",
       "      <td>0.267788</td>\n",
       "      <td>0.433932</td>\n",
       "      <td>-0.114450</td>\n",
       "      <td>0.268179</td>\n",
       "      <td>-0.611011</td>\n",
       "      <td>0.960324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>-0.694635</td>\n",
       "      <td>-0.531606</td>\n",
       "      <td>-0.732749</td>\n",
       "      <td>-0.666293</td>\n",
       "      <td>-0.553944</td>\n",
       "      <td>-0.896863</td>\n",
       "      <td>-0.839197</td>\n",
       "      <td>-0.948554</td>\n",
       "      <td>0.004817</td>\n",
       "      <td>-0.472587</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.640114</td>\n",
       "      <td>-0.303858</td>\n",
       "      <td>-0.695427</td>\n",
       "      <td>-0.614186</td>\n",
       "      <td>-0.466152</td>\n",
       "      <td>-0.634876</td>\n",
       "      <td>-0.700811</td>\n",
       "      <td>-1.055439</td>\n",
       "      <td>-0.339337</td>\n",
       "      <td>-0.278182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>169</td>\n",
       "      <td>2.215126</td>\n",
       "      <td>0.287157</td>\n",
       "      <td>2.328490</td>\n",
       "      <td>2.466473</td>\n",
       "      <td>-0.314523</td>\n",
       "      <td>1.496564</td>\n",
       "      <td>1.510580</td>\n",
       "      <td>1.555440</td>\n",
       "      <td>-0.433059</td>\n",
       "      <td>-0.241249</td>\n",
       "      <td>...</td>\n",
       "      <td>2.438746</td>\n",
       "      <td>0.257482</td>\n",
       "      <td>2.604231</td>\n",
       "      <td>2.664237</td>\n",
       "      <td>-0.343096</td>\n",
       "      <td>1.130187</td>\n",
       "      <td>1.220513</td>\n",
       "      <td>0.983564</td>\n",
       "      <td>-0.262125</td>\n",
       "      <td>0.140716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>-0.621525</td>\n",
       "      <td>0.666905</td>\n",
       "      <td>-0.584446</td>\n",
       "      <td>-0.619262</td>\n",
       "      <td>-2.194813</td>\n",
       "      <td>-0.092136</td>\n",
       "      <td>-0.212902</td>\n",
       "      <td>-0.585500</td>\n",
       "      <td>-2.233215</td>\n",
       "      <td>0.373450</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.823927</td>\n",
       "      <td>0.338108</td>\n",
       "      <td>-0.654594</td>\n",
       "      <td>-0.746618</td>\n",
       "      <td>-2.066315</td>\n",
       "      <td>0.240887</td>\n",
       "      <td>-0.055814</td>\n",
       "      <td>-0.186356</td>\n",
       "      <td>-1.180096</td>\n",
       "      <td>0.419792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>171 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0      -0.820383     -0.173809       -0.864054  -0.772484        -0.839113   \n",
       "1      -0.141927     -0.792820       -0.198179  -0.230883        -1.152495   \n",
       "2       1.127255     -0.621604        1.062181   0.984540        -0.660692   \n",
       "3      -0.981224      0.993971       -1.003433  -0.874237        -1.236369   \n",
       "4       0.574547     -1.058424        0.501265   0.422529        -0.242850   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "166    -0.916888     -0.625994       -0.917171  -0.839925         0.729320   \n",
       "167    -0.109758     -0.854282       -0.088121  -0.216093         0.195580   \n",
       "168    -0.694635     -0.531606       -0.732749  -0.666293        -0.553944   \n",
       "169     2.215126      0.287157        2.328490   2.466473        -0.314523   \n",
       "170    -0.621525      0.666905       -0.584446  -0.619262        -2.194813   \n",
       "\n",
       "     compactness_mean  concavity_mean  points_mean  symmetry_mean  \\\n",
       "0           -1.115846       -0.895059    -0.803603       0.581700   \n",
       "1           -0.871458       -0.875741    -0.842076       0.091697   \n",
       "2            0.192327        0.150940     0.302088      -0.436534   \n",
       "3           -0.830667       -0.999770    -1.171264       0.453118   \n",
       "4           -0.490922       -0.513499    -0.165548      -0.384406   \n",
       "..                ...             ...          ...            ...   \n",
       "166         -0.615620       -0.815449    -0.720426      -0.457386   \n",
       "167          0.278202       -0.231850    -0.018971      -0.638096   \n",
       "168         -0.896863       -0.839197    -0.948554       0.004817   \n",
       "169          1.496564        1.510580     1.555440      -0.433059   \n",
       "170         -0.092136       -0.212902    -0.585500      -2.233215   \n",
       "\n",
       "     dimension_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         -0.557191  ...     -0.867791      -0.052852        -0.896889   \n",
       "1         -0.935263  ...     -0.349774      -0.954952        -0.300309   \n",
       "2         -0.788529  ...      0.807410      -0.679606         0.724717   \n",
       "3         -0.064110  ...     -0.727843       0.754930        -0.758478   \n",
       "4         -0.662945  ...      0.249706      -1.050791         0.202296   \n",
       "..              ...  ...           ...            ...              ...   \n",
       "166       -0.048247  ...     -0.857347      -0.007215        -0.877674   \n",
       "167        0.250510  ...      0.011585      -0.856071         0.034161   \n",
       "168       -0.472587  ...     -0.640114      -0.303858        -0.695427   \n",
       "169       -0.241249  ...      2.438746       0.257482         2.604231   \n",
       "170        0.373450  ...     -0.823927       0.338108        -0.654594   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0     -0.798979         -1.019902          -1.079349        -1.007702   \n",
       "1     -0.418776         -1.077035          -0.417112        -0.746220   \n",
       "2      0.699342         -0.382650          -0.081638         0.551709   \n",
       "3     -0.715669         -0.641946          -0.689611        -1.066559   \n",
       "4      0.080185         -0.633156          -0.637230        -0.321219   \n",
       "..          ...               ...                ...              ...   \n",
       "166   -0.777207          0.083204          -0.778482        -0.869224   \n",
       "167   -0.163628          0.267788           0.433932        -0.114450   \n",
       "168   -0.614186         -0.466152          -0.634876        -0.700811   \n",
       "169    2.664237         -0.343096           1.130187         1.220513   \n",
       "170   -0.746618         -2.066315           0.240887        -0.055814   \n",
       "\n",
       "     points_worst  symmetry_worst  dimension_worst  \n",
       "0       -0.923140        0.358435        -0.918749  \n",
       "1       -0.800681        0.438508        -0.516902  \n",
       "2        0.505600       -0.249256        -0.219070  \n",
       "3       -1.382204        0.061024        -0.559531  \n",
       "4       -0.128562       -0.340767        -0.908518  \n",
       "..            ...             ...              ...  \n",
       "166     -0.731329       -0.026197        -0.414593  \n",
       "167      0.268179       -0.611011         0.960324  \n",
       "168     -1.055439       -0.339337        -0.278182  \n",
       "169      0.983564       -0.262125         0.140716  \n",
       "170     -0.186356       -1.180096         0.419792  \n",
       "\n",
       "[171 rows x 30 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scaling for the testing data\n",
    "scaled_X_test =pd. DataFrame(scaler.fit_transform(X_test),columns=X_test.columns)\n",
    "scaled_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fir transform ---> fit and transform \n",
    " #fir --->it will find parameterss -->mean and variance of the X_train columns\n",
    "#transform -->whatever the mean and variance is caluculated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=6, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model Building :\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn=KNeighborsClassifier(n_neighbors=6,metric='euclidean')\n",
    "## apply the knn object on the dataset(Training phase) \n",
    "\n",
    "## syntax objectname.fit(input,output)\n",
    "knn.fit(scaled_X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B', 'B', 'B', 'M', 'B', 'M', 'B', 'M', 'B', 'B', 'B', 'M', 'B',\n",
       "       'M', 'B', 'M', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'M', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'M', 'M',\n",
       "       'M', 'M', 'M', 'B', 'B', 'B', 'M', 'M', 'B', 'M', 'B', 'B', 'B',\n",
       "       'M', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'M', 'B', 'B',\n",
       "       'M', 'B', 'B', 'M', 'M', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'M',\n",
       "       'B', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'M', 'M', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'M', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'M', 'M', 'M', 'B', 'B',\n",
       "       'M', 'M', 'M', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'B', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'M',\n",
       "       'B', 'M', 'B', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'B', 'M', 'M',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'M', 'B',\n",
       "       'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'M', 'B', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'M', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'M', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'M',\n",
       "       'M', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'B', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'M',\n",
       "       'M', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'M', 'M', 'B',\n",
       "       'M', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'M',\n",
       "       'B', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'B',\n",
       "       'M', 'B', 'M', 'B', 'M', 'B', 'M', 'M', 'B', 'B', 'B', 'B', 'M',\n",
       "       'B', 'B', 'M', 'M', 'B', 'B', 'M', 'B', 'M', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'M', 'M', 'B', 'M',\n",
       "       'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'M', 'M', 'B', 'B',\n",
       "       'B', 'B', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'B', 'B',\n",
       "       'B', 'M', 'B', 'B', 'B', 'M', 'M', 'M', 'B', 'B', 'M', 'M', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'M', 'M', 'M', 'B',\n",
       "       'M', 'B', 'B', 'M', 'M', 'B', 'M', 'B'], dtype=object)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction on the data\n",
    "# predict function ----> gives the predicted values\n",
    "# syntax:object nam.predict(input)\n",
    "y_train_pred=knn.predict(scaled_X_train)\n",
    "y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.97      1.00      0.98       257\n",
      "           M       1.00      0.94      0.97       141\n",
      "\n",
      "    accuracy                           0.98       398\n",
      "   macro avg       0.98      0.97      0.97       398\n",
      "weighted avg       0.98      0.98      0.98       398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# chect the accuracy , classification report \n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_train,y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9473684210526315,\n",
       " 0.9239766081871345,\n",
       " 0.935672514619883,\n",
       " 0.9298245614035088,\n",
       " 0.9473684210526315,\n",
       " 0.935672514619883,\n",
       " 0.9473684210526315,\n",
       " 0.9415204678362573,\n",
       " 0.9473684210526315,\n",
       " 0.9298245614035088,\n",
       " 0.9415204678362573,\n",
       " 0.9298245614035088,\n",
       " 0.935672514619883,\n",
       " 0.9239766081871345,\n",
       " 0.9239766081871345,\n",
       " 0.9239766081871345,\n",
       " 0.9473684210526315,\n",
       " 0.9239766081871345,\n",
       " 0.935672514619883]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for the optimum k-values \n",
    "# build the models with multiple k values -->error\n",
    "from sklearn.metrics import accuracy_score\n",
    "scores=[]\n",
    "for k in range(1,20):\n",
    "    knn_model=KNeighborsClassifier(n_neighbors=k)\n",
    "    knn_model.fit(scaled_X_train,y_train)\n",
    "    pred_test=knn_model.predict(scaled_X_test)\n",
    "    scores.append(accuracy_score(y_test,pred_test))\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2817dde2488>]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOydeXxU1fn/P2f2zJJtkkwSQgiQBcISkB1lcUNQkCpqtVq11dpW7KLiQlu11faHVtp+bYutS11btdYNQRRFQVSUnbAEEgKEkG2yJ7Nk9vP7Y+bGSTKT2e6dmcyc9+vFi+TOXc7kztznnGf5PIRSCgaDwWAkH6JYD4DBYDAYsYEZAAaDwUhSmAFgMBiMJIUZAAaDwUhSmAFgMBiMJEUS6wGEQlZWFi0qKor1MBgMBmNEsX///nZKafbg7SPKABQVFWHfvn2xHgaDwWCMKAghZ31tZy4gBoPBSFKYAWAwGIwkhRkABoPBSFKYAWAwGIwkhRkABoPBSFJGVBZQOGw82IANmypRa6YoVhKsXlGBldMLYj2smBEPf494GEM8jYMRnyTF54NSOmL+zZgxg4bCewfO0Qvufo1+VTiF2kRi+lXhFHrB3a/R9w6cC+k8iUI8/D3iYQzxNA5GfJJonw8A+6iPZ2rMH+qh/AvVAFz6u830q8Ip7rfp+fdV4RR66e82h3SeRCEe/h7xMIZ4GgcjPkm0z4c/A5DQMYBaM8WshqoB22Y1VKHWnJw9EOLh7xEPY4incTDik2T5fCS0AShWEuwtKB+wbW9BOYqVJEYjii3x8PeIhzHE0zgY8UmyfD4S2gCsXlGBB1atxa7CKbCLxNhVOAUPrFqL1SsqYj20mLB6RQXWXPVgTP8evu7J/TG4J+yzwRiOePiuRIOEzgJyR+wXYE2KEs0OEcYrCdZcOS3xIvlBsnJ6AbYfn4DbRQ+hT6pAsYpgzYro/j24e3K/UokmuxgKex+WzyuJ+j3hxvFwmganzMAYuQtrrjovaT8bjIGsnF6A7Se470oKSlQEaxIwCyihDQDg+aITgl+8cQj//OkiFOeoYz2kmJKhkcMsUwIANvx4IUp1mqiP4fKp+Vjz1mHcsXgcHE4Xlk7OjfoY7E4XqvVGPHPnYozPTu7PBMM3uelKmGVKXFiWjRd/MDvWwxGEhHYBcRRkKHFeYTpcNLECOOHQ1N3X/3N1iyEmY6hrN8HupJiQq8FvlpdjZlFm1MfwVW07nt5xCqdajaCUwmxzRH0MjPhmYUkWAKDTZIvxSIQj4VcAADBjTAbeufP8WA8jLmjusWDuuExcUJyFCbnRn/0DQLXebXhKdO6Zd22rAb0WB84rzIjaGDYfboZGLsGismzc9vI+dJpseG81+4wwvmV+cRaunj4Ku890xnoogpEUBoDxLT9ZNB4KqQgXTdDFbAw1LQaICPpdL3e9dhBKmThqRtrqcGLr0RYsmZQLuUSMLLUMRxt7onJtxsihrt0EkYigw2QFpRSEJFYGEJAkLiCXi2LZU1/guZ2nYz2UmHP5lDxcNEGHLpMN+8/GZmZTrTegKEsFhVQMAFhRkY8D9d1o6DJH5fqfV7fBYHVgeUUeACAvLQVtRitsDldUrs8YGdz0r934+lQH1iwpgytBvcdJYQBEIoKWnj6c7TTFeigxxWh14EB9F0xWB17aVYdr/vk1LHZn1Mfx5+um4YVbZvX/vmJqPgDgg8PNUbm+3mBFQUYKLih2+3jz0xWgFND3WqJyfcbIoMNow+VTcnH7gnEQixJv9g8kiQEAAK1ajg5j4gZzguFIQw+ufnoXDtZ3oyxXA0qB2lZj1MehkktQlKXq/71Qq0RFQRo2R8kAfH/uGOy870JIxe6Pf15aCgB3fITBAACzzYE+uxOpCinOtJtgtCZmkkDyGACVLOkNQHOPOwMoL13Rn/5Zo49uJlBduwlPfHQCjV7ZSIDbDVStN6DNYBX0+n0294pH5DWjK9Vp8LOLipGjkQt6bcbIgXtWtBmtuHD9DnxzqiPGIxKGpDEAWWo52k3CPlziHW6Gm5+WgiKtEjKxqD8jJ1ocPNeFf+w4hb5BaZffnTUa+39zCbIFfgjf8+Yh3Pj8NwO25aYpcO+SsgGrEkZy0250Pyu4iVJHgj47kiYLaMaYDKjk4lgPI6Y0dvchQylFisz9dxiXrUJNlGsBqluMkIlFGKMd+LDVKKSCX9todeCzE624YXbhkNe6TDZYHS7kpikEHwcj/hmVkYJ1V0/B/PFaAEB7gnoPksYA/PCCsbEeQsxp7u7r93cDwG+vnIS0FOEfvN7U6A0Yl63q9797U9XUi7XvHsGT10wVpEJ5W5UeVocLy6fmDXnthue+QUFGCp73Ck4zkpccjaJ/oqCWSxLWfZw0BoAB/OKSUpi8gllzx2mjPobqFgNmjPFd8JWtkeNIQzc2VzbhniVlvF97U2UT8tMUPgvO8tNT0NjNgsAMN/UdZvT02TF5VCq0alnCuoCSJgaws6YN0x79GFVNvbEeSsyYNjod53tSHwGgp8+Odw404FxndPLvLXYnjFYHyvxUIGdr5Jg3XotNh5vd3Yp4pMdsx86TbVhekT8gAMyRl6boD5IzGC/tqsP1z34NQgjuu6wM188a6jZMBIIyAISQpYSQakJILSHkQR+vjyGEfEoIOUwI2UEIKRj0eiohpJEQ8nevbTs85zzk+ZcT+dvxT4pMjG6zPWEteSAsdic+ONyMFq9Uxx6zHfe8WYmvatujMgaFVIxDD1+KHy0Y53efFVPzcabdhGM8G2q5VIT111bgupmjfb6en56CbrO9P0uIkdx0mKzQqt0JCcun5mPe+OivlqNBQANACBED2ABgGYByADcQQsoH7bYewCuU0qkAHgWwbtDrjwH43Mfpb6SUTvP8aw159CGgVckAIGF9eYFo6DJj9WsHsPvMt+lsBRkpSJGKo5oJRAiBTOL/Y7d0ci4kIoJNh5t4va5CKsbKaaP8qsHmeYK/TWwVwIBbAC7T88xo6bFgX11i6gEFswKYDaCWUnqaUmoD8AaAlYP2KQfwqefn7d6vE0JmANAB+Djy4YYPZ8259K5ko8nj3/YOAotEBKU6ddRqAZ7/4jR+/e6RYfdJV8rw40XjMGVUGm/X7TBa8cznp9AxzL2fOSYT/++qKchUyni7LmPk0m60IUvt/iy8+k0dvvvsN3AloB5EMAZgFIBzXr83eLZ5UwlglefnqwBoCCFaQogIwJ8A3Ofn3C963D8PET9KS4SQOwgh+wgh+9ra2oIYrm9SFRJIxQQdCSztOhycfzs/fWCaY4lOgxp9dKqBd1S34UgQomv3XTYByz3yEHyw5WgL1n14Am3DGIBCrRLfm1OIDBUzAAz3pEGrck8atSo5nC6Knj57jEfFP8EYAF8P5sGmcA2ARYSQgwAWAWgE4ABwJ4AtlNJzGMqNlNIpABZ4/n3f18Uppc9SSmdSSmdmZ2cHMVzfEEJw/axCTMxLDfscI5mmbgsIAXSpAw1AmU6DNoM1Kprn1XpD0OmdHUYrb8vuzZVNKM5RoyzAtauaenG6LfrSGIz448lrK3DT3DEAAK1nJZCIk8dg0kAbAHhHzgoADHDQUkqbAFwNAIQQNYBVlNIeQsg8AAsIIXcCUAOQEUKMlNIHKaWNnmMNhJDX4HY1vRLxOxqGx74zWcjTxzVN3X3I0ciH5N9fM6MAK6fnI0MpbD1Ap8mGNoM14EOY49fvHsWB+i58vfbiiIS4Wnos2FPXiV9eXBpQzveWF/fgorIcPHHN1LCvx0gMFpV+O9nkVgIdRmvCdRQMZgWwF0AJIWQsIUQG4HoA73vvQAjJ8rh7AGAtgBcAgFJ6I6W0kFJaBPcq4RVK6YOEEAkhJMtzrBTAcgBHeXlHAUhWyd+7Ly3FczfPHLI9QyVDjkYhuNY5F2coDbIJzRVT89BqsGJvhKuAD440g1L0Sz8PR36aggWBGegx2/FJlb5/VZzIK4CABoBS6gBwF4CtAI4DeJNSeowQ8igh5ErPbosBVBNCauAO+P4hwGnlALYSQg4DOAS3y+i58N5C8Dzw1mFc9KcdQl8mLslPT8HUgnSfr728qw5v7vPlpeMPm8OFUl1gNwzHxRNzkCIVY1NlZNlAjV19mFqQFlTf37y0lAEtMxnJSbXegB+9sq+/ZqgwU4l/3nSe3wLGkUxQlcCU0i0Atgza9rDXz28BeCvAOV4C8JLnZxOAGaENNXI0isQt6R4OSile/KoOc8dpUZ4/NAay2ZNy6S9Hng8Wlmbj49JFQe+vlElwSbkOHx5twe+unASJD+mIYHh4RTnszuBWfXnpCuw82Zaw3Z8YwcFli3Ezf5VcgqWTA68gRyJJUwkMuFNB++zOpGsA3m2249HNVdh1ynfBV6lOg+oWA+/Vt5GyfGoeOk02VDaE166Re/D70h3yRX5aCsw2J3r7kuvzwRhI+yDXDwB8c7oDlee6YzUkwUguA5CkxWBN/SmgKT5fL9Vp0GtxoFUgLX5KKS7+0w48/0VoLTkXl2XjywcuDHvpveofu/Db948Fvf+SSTq8eOssyKVJ9bVgDIJbAXjXhDz03lE8s/NUrIYkGEn1SU/kYM5wNPcXgfmWOuZSM6sFkoZuNVhxqs0U9EycQy4RoyBDGdY1T7cZcbihB6Mzgz9+jFaFCyfk9PcqZiQnHUYbMpTSAW7HTJUsISWhk8oAFOeo8eOF4wRPeYw3uCKwUX5XAGpIxUSwnrhcBlCJLvQUulaDBT96ZR+2V4emFLL5cDMIAa6YErzv1uF0YVuVPupd0hjxxR0Lx+H5WwZmzGWp5cNWko9UksoAjNGqsPbyiUOakSQ6jd0WSMUEWWrf3ba0ajmqHl2KawUKAnMri2AzgLzJUMqwt64T7x1sDPoYSiner2zCrKLMkBq8EELwk3/vx8ZDwV+LkXiMzlRixpjMAdvcktBsBTDiMVod6LUkXkn3cPzykhJ8du9inzLIHKG6Z0KhRm9AllrWr8cUClKxCMsm52JblT5opc5qvQG1rUas8NH4ZTjEIgJdqqLfZcZITjYeasSB+q4B27QqObrN9qAzykYKSWcA5vxhG/667WSshxFVFFJxQF/4h0eacfMLewQRvCrPS8WqGQWBd/TD8qn5MNmcQbuBcjQK/OaKiVgWgvuHIz9dMaRhPSO5eOT9Y3j3wMBV4KoZo/DunfMhSrD04KQzAJkJupQbjqe2ncSOAA/P7j47dta0CfLwu/X8sVi7bGLYx88Zm4kstay/XiEQmSoZbl8wzq/Lazjy0lLQ3MNWAMmK3elCt9k+IAUUAAoylJhemBGRLEk8knQGQKuSJ5UktNNF8bfPTmL3meElFYTKBLI5XLDYI2uyIhGLcNsF4/xWMntT22rEuwcbwr5mXroCLT2WhJT+ZQSmq78GYODkodtsw5v7zkWte160SDoDkKWWJVUdQLvRCoeLIj9AMLTUk6FT08qvAfjiZBsmPbIVR8Is5uL46eLx+Mmi8QH3e3PfOdz/1uGwDcD3547B+z87P6xjGSMfLtUza5AseIfJhvvfOoz9Z7t8HTZiSToDoFXJk6otJKdt490IxhcahRSj0lNQw/MKoFpvgNNFMSYrvHx+byx257BfQJeL4oPDzVhYko30MBu7FGQoMSE3ddiAOSNx4Z4Ng1cAWarEbCiVdAbgiql5WH1hcayHETU4f7a/KmBv5o/XIi2F3xqJmhYD8tMUSFVEft6/bKvB9c9+jR6z7yyug+e60NjdF5Typz8MFjte/bpOsKI4RnwzqygT2+5ZiMmjBmpmpaZIIBElXkOppDMAC0uzcfO8olgPI2pwM5bBncB88eS1FfjdSn57JlTrjUFLQAfi8sl5sDsptla1+Hx9U2Uz5BIRLpmoC/saNocLD208hq9qfesmMRIbhVSM4hwNlLKBOpmEEHctAFsBjGwsdidqWw1JIwh387winHhsKe8z+2BwOF041WoMugtYIKYWpKEwU+lXIvpUmxEXluVAE8FqI1Mlg1wi6q+eZiQXX5xsw6tf1/l8TauSJ1z8MOkMwN66Tlzy55042tgb66FEDYVUHJS8cX2HGReu34GPjvqeYYeKw0Vx/9IyLCkPf0buDSEEy6fmYdepDp8zsVdvm4O/fHdaxNfIT09BEysGS0o2Vzbj79trfb729I3n4fFVidUtLukMgHd7t2Tgjx+dwGu764PaN1sjR12HCSda+DGOCqkYty8Yh5lFmYF3DpLlU/PhdFF8dmJgXQOXtpkii1zILY91BktaOkzfNoMfTFGWCtma0GtL4pmkMwBZngKP9gQL5vjjrf0NOHQuuNS1FJkYYzKVvImh1bWbeC8sm5inweafXYBrvCqL7U4XFj653e/SPVTy0lKYHESS0m60DSkC49h/tgsb/KwORipJZwAy+nsCJP4KwOZwoc1oDZgC6g3XHIYPntxajRuf+4aXc3EQQjB5VNoAl9ZXte1o6OpDbgjvczjWXj4BW+9eyMu5GCOLTpPNbwX5njOdeHJrdULFD5POAEjFIqQrpQkXzPGFvtcCSoPLAOIoy9WgrsMccfUu4K4B4CsA7I3N4cKv3j2CN/e6+xhvqmyGRiHBwtIsXs6fpZbHJGjOiD0dRisyVb5XAP39RBLo2RFUT+BE43dXTgqpUchIJZQaAI45Y7Vo7bWiz+aMqDGK1eHEmXYTlk7KDfsc/pBJRDhY343jzb1YOT0fHx9rwWWTcyGX8NPIpam7D//+5ixWzSgIqpk8I3H45lcXw58KSJZXQ6lEeX4kpQFYOW1UrIcQFUxWBzKU0pBcQBeUZOGCkshn0qfbTHC6KG81AINZPjUPT26txmu762GwOrCiIp+3cxutDjy94xQm5KUyA5BkDJdCnIgJJElpAM51mtFqsAxp+pBoXDghBwcfXhLycS4XhdHmiKh6lwskh9MEJhhSxCIobWY8+v4x6EQOdBj4C9pyrTOboyQLvfFgAzZsqkStmaJYSbB6RQVWTg9fPpsRHmc7THhtdz2+N6fQZ9OoRGwpm5QG4Nmdp7H5cFNYD8dk4Kqnv0K2Ro7nb5kV9jnmjdPibzdMx9gs/ruvbTzYgBff243n316HWQ1V2FtQjgesayEWLeDlwalRSKFRSPp1lIRk48EGrH/1Czzh/V661wLg570wgqe21Yhndp7Gsil5GKMd+npeWgr2/eYSZISpMxWPJF0QGHBb8i6zHY4E6+4zmHVbjmPdluMhHzc6U4nqCFNBc1IVWFGRD5mE/4/Yhk2VeOLtdZhffwRSlxPz64/gibfXYcOmSt6ukZ+WgqYo9AWIxnthBAc3s9f6CQKLRe62qonUEyBJDYDbl9dpTpylnC92nmzHyVZjyMeV6TQ419kXUbrbxkONONUW+rWDodZMMauhasC2WQ1VqDXzp+Gfl67o14YXkmi8F0ZwcNk9/uoAAOCFL8/0Z58lAklpALJUiZfO5Yvmnr5+f3YolHj89if14T3AzTYHfvHGIXxwuDms4wNRrCTYW1A+YNvegnIUK/mbmT3z/Rn430/m8XY+f0TjvTCCo8NoRYpUPEQIzpv3K5uwKcjOdCOBpDQA/SuABArmDKbP5kS32R5SCihHmSdzJ1w3UK1n1SFEDQAArF5RgQdWrcWuwimwi8TYVTgFD6xai9UrKni7hlwSnH5SpKxeUYH7rxb2vTCCw2BxDDv7B9ypoO0JNHFMyiBwmU6D526eiQkCpSjGA5yWTShFYByFmUr84uISTMpPDbyzD7hKYq7LGN+4g6ML8Nv01P7MmTU8Z84cbezBv748g/suKwvLiAbLyukFqGqqwO3kIfRJFcgROfGr62ayAHAMeOKaqbA5ho8LZqpkONIYWXe7eCIpDUCaUopLeVKojFcsdifK81JRmBl6Fo5YRHD3paVhX7tGb4BMIvKZSscXK6cXCPqQ7LXY8e7BRlw7o0BQAwAAM4oysW1UNqwOF8ZmqdjDP4YESlrQqt2S0JTSqKwQhSYpXUAA8HlNG44mkCUfzKT8NGz5xQLMGJMR1vEGix0H6sPrf1qtN6IkRz2isyVGeR760cgEWjIpF5/euxizizJ5E+JjhM5D7x3F+356TXBwGUK9lsTQA0paA3Df/yrx6tdnYz2MuOU/u+tx9dO7/LZfHI6/XT8df7thugCjih65nuB5NGoBOEpzNdD3WsP6mzMig1KKN/bW43jz8FLot8wvwsk/LEsYraikNQBadWI3h1/34XHc/vLesI/nKnhrWkOfkaYppRg3wiUU5BIxstQywTuDOV0UC/+4Hf/+5iwm5qVifLYKbQkkNTBS6LU4YHdSvzUAHFKxKCFcPxxJawCy1LKEKukeTFVTL9oM4T9IOA2fUKWhT+oN+MsnNWjlUZohVhTnCG/EznWaUd9phkwswqLSbHx67+KoXJcxEE7fx58UNEerwYL736rE/rOd0RiW4ARlAAghSwkh1YSQWkLIgz5eH0MI+ZQQcpgQsoMQUjDo9VRCSCMh5O9e22YQQo54zvlXEmWzmqmSJXQdQHOPJSQRuMHkpymglktwMkSf9O4znXjq05MBsylGAm/cMQ/rrha2BSCXaiuUaB4jOPqrgAOkgYICb+5rwPHmxIjVBDQAhBAxgA0AlgEoB3ADIaR80G7rAbxCKZ0K4FEA6wa9/hiAzwdt+weAOwCUeP4tDXn0EeBu8JyYS21KKZq7+5AXRgooByEEJTp1yLUAJ/UGqGTi/iAqY3hqPCusEs+s/9FNVVj92oFYDikp6bM5ka6U+m0HyZGRYEWkwawAZgOopZSeppTaALwBYOWgfcoBfOr5ebv364SQGQB0AD722pYHIJVS+jWllAJ4BcB3wn4XYXDr/CK8ccc8uC+fWPRaHDDZnMiPsEPWg0snYO2yiSEdU603oDRXkxB+0u0nWvHdZ75Gr0W4oGxNqxEFGSlQyd0Z2X12B3bVtifk5zKeWViajUMPL0F5gNqX/oZSCRI/DMYAjALgLX7R4NnmTSWAVZ6frwKgIYRoCSEiAH8CcJ+PczYEOKegFGqVmFKQlhAPqsFY7U5cMjEHE/IicyvMGadFxej0kI6p0RsFk4CONgarA7vPdAraH3jKqFRcNf3bj35JjgZdZntCVZsmGtoEch8HYwB8PSEHT0/WAFhECDkIYBGARgAOAHcC2EIpHayeFMw53TsScgchZB8hZF9bW1sQww2OVoMFr++pR0sU8ryjTU6qAs/fMgsLSrIjOo/J6sCmyibUtZuC2r/HbIfF7hRMAiLajPK40JoEzAS6Y+F43LukrP93ToaD1QNElxe+PIP73wpOgbUgQ+n7CTYCCcYANAAY7fV7AYAB1RKU0iZK6dWU0ukAfu3Z1gNgHoC7CCF1cMcJbiaEPO45Z8Fw5/Q697OU0pmU0pnZ2ZE90Lxp7OrD2neOBMz7TWbMNid+9vpBfHaiNaj905RSHP3tZbhxbqHAI4sOXBBdqBWA1eEcEiznjGeo2VeMyNh/tgv7zgZX+PjyD2djw/fOE3hE0SEYA7AXQAkhZCwhRAbgegDve+9ACMnyuHsAYC2AFwCAUnojpbSQUloE9yrhFUrpg5TSZgAGQshcT/bPzQA28vOWgoNL92pPwEDwnz6uxgVPfBaxHzlLLUOmShbSbFQkIrz15o01ORo5RES4YrCPj+lR/vBHqPWqtchSy3DZJB2yNcMHIxn80m60IitAADgRCWgAKKUOAHcB2ArgOIA3KaXHCCGPEkKu9Oy2GEA1IaQG7oDvH4K49k8BPA+gFsApAB+GPvzwScT2bhwNXX2gFBHHNwghKNWpgzYA//z8FP7wQVXgHUcIErEIc8ZqoVEII5lVozeAwuNS8EAIwTPfn8lrj2NGYDpMtsApoB4+OtqCm1/YA3sCNJQK6pNNKd0CYMugbQ97/fwWgLcCnOMlAC95/b4PwOTgh8ovSpkEKVJxQqaCNnX3haUC6otSnQbvHGgMSvzq42MtkIoTq7bw9TvmCnbu6hYDirRKKKRDV0w2hwtSMUnIJIV4pMNoxdxxwfUIbzNYsLOmDV1mG3I0/HzPYkVifVtDRKtOnGi+N5EWgXlTqtPAaHUEFEWjlOKk3tgfxGQE5mSr77/XxkONKH/4IzQnYIJCPOJyUeSmpWBMkMq5XD+RRHh2JKUcNMert81BeoKIOnG4XBQtPRbkTeFnZrJ8ah4Wl2UjL3X48zX3WGCwOvq7iSUKr35zFi/vqsMndy/kdTZusTtR12HClT5cPfnpKXC4KKr1BsGlqBnuuNWHv1gQ9P7aBCoGS+oVwNgsVX9lX6Jgc7rw3VmjMWdscMvZQKQrZSjIUEIUQNqZqxhOlBoADofThdpWI+/d4xwuirXLJuDCCTlDXivN8aSCskyguKR/BZAAxWBJbQB2nWrHsztPxXoYvKKQivHYdybjogn8Nbz57956vLGnfth9bA4XirRKwbqAxYr+VFCe3TFquQR3LByPaT4K7dKUUuhS5WG35GSExv6zXVj1j11BJztkqWUYm6WCKAHiM0ltAHbWtGP91pqEKru32J1w8JydsPlwM/69e/jeCZdNysWO+y5EujKxVlT9jWF4TgU93WYcVmq6VKdhxWBRoqHLjP1nu4J+oKcrZdi+ZnFCZGoltQHIUstgc7pgsCZGdx8AeG13PUp/8yG6zfy5LMp0GpzUG+F0JY6hDBZOUI9vA/DY5ir84EX//RqunTka15zHWkNGA86XnxVkGmgikdQGoL8WIAGCORxN3X2QikW8diwqzdXA6nDhXKfZ5+tOF8VF63fgtd3Du4lGIlqVDIvLspHNc7pfTYCMqSsr8nHr+WN5vSbDN50mGyQiglRF8N+Zte8cwW/fPybgqKJDUmcBcdKvHUYrxmYJ18A8mjT3WJCfnsJrxgoX2K3WG1Dk4+90rtOM0+0mSEZwD2B/EELw0g9m83pOg8WOxu4+fE/nXzKDUoqWXgskIhGrChaYDpMVGSpZwEQHbxq6zDAmgOeArQCQWHIQTT19yEvjd7ZaolNDIiJ+hfOSoakJn3Gik61GAMNnTJltTsxb9xleDxB8Z0RObmoK5o7ThnRMoiiCJvUKoFSnwcGHLk2YBs+AW7js/OIsXs+plElw7NHL/Gr8DG5qkmj8fnMVPj3RihCv30MAACAASURBVO1rFvNyPu7vNZwLSCWXYHRmCgsER4FfXFIS8jFadWI0lEpqAyAVixKuDuDW84tQLEBD9uEE3qr1BozO/LapSaIhl4pQ32mG00Uh5sHNtagsG09dPy1g17QylgkUt2jVMphsTljsTp9SHiOFpHYBAcCG7bXYeKgx1sPgjZ8sGo9LyvmrAeDYfqIVt7ywx2ev3/L8VJ8VrYlCXloKnC7KW6P7vLQUrJw2KqDPuVSnwek2U0L0V45nLv3z53hu5+mQjhmXpcbccZnoszkFGlV0SHoD8Pb+BnxcpY/1MHiBCy4Kka7Z02fH5zVtqOsY2hzmzsXFuO+yCbxfM174thaAHwPw9v4GnAmiyU5ZrgYOF/X5N2fwg8XuxMlWI2wh1s4snZyLN+6YN+I9CElvANyCcCPflwcA26vbcP7jn+F0m5H3c/trVGJzuBJCFnc4+KwF6DTZcO//KrEtiEnHnLFaPHX9NOhGuOJkPMPJwWtH+IM8XJgBUMkTIpoPfPuAyhNAQGxctgpiERnik/64qgWTHt6K2lb+jU68MCo9BdfNLOBFYrsmhIyp3DQFVk4bhTRl4iQpxBvc5I/T9wmW1l4LLlq/Y8S7jxMzahcCWrUMe+sSwwA0d/dBo5BALUAwViEVo0irHLICqGkxwEkpCjISV7VSo5Dij9dU8HKumhBF844396LdaI24vzPDN9zkL9hmMBxqhQSn2028uQVjBVsBqGQw25wJIXPQ1GNBPk99AHwxe6wW6kHdsar1Bozx09QkkaCUwmCxR3ye6hYDUhUS6FKDm3H+7bOTeOi9oxFfl+EbjUKCSybqQq6d4RpKdY5wRdCkXwH8/OIS3H1paUJ0Xmru6ev3VwvBuqunDNlWozdiQgIXgHHc9vI+tBms2PSzCyI6T43egLJcTdCft5IcDT482jLi0w3jlZlFmXi+KDzp9MwEKAZLegMgSaAWhnddWAx5FB8SwzU1STRyNHIcbuiO+DzPfn8mevqCX0mU5WpAKVDbasTkUWkRX5/BH1lqGdpHeE/xxHn6hUl9hxn3vHkIx5p6Yj2UiFk6OQ8Xlg1tMMIXrb0WLPnL5/2BL7vThTVLyrC4LPH903lpKWg32mB1RJb3naGS+dRT8oe/7CsGP9z/ViWu/PuXYR27sDQbU0e4UU56A2BzOvHOgUacahvZudYGix376joFFajKVMlQ125GVVMvAHdwdPWFxZhemCHYNeMFLgPInx5SMBxr6sFT206G1F2sSKuETCxCTSszAEKg77UiXOfvvUvKsOayMl7HE22S3gB4K4KOZI409OCaf37Ni5vCHxKxCONz1P2ZLHXtJt6qY+MdrjdvYwS1AF+f6sBfttWEdIxELML/fjIPP100PuzrMvzTYbKGnAKaSCS9AUhLkUIsIiM+mNPkmZkKmQUEAKU6NWr07pz/3206hpv/tUfQ68ULJTlq/OLikoj+vtUtBmSp5cgMseioYnR6wnVaixc6jLawi8Be31OP8oc/CimmE28kvQEQiQgylLIR3+CZKwLL5VkKejClOg0au/tgsNgDNjVJJHJSFbj70tKQ/PeDqWk1oiw3dKG+2lYjntp2kpc0VMa3UErdBiDMFYBCKoLZ5gzJpRdvJL0BAIAxWuWITwNt7umDViUTPFVw5pgMXD19FNoMVjR29/UHKZOBDqM1bDkIl4vipN6AkpzQ/1517Sb8ZVtN/8qLwQ92J8V1swowc0x4MaxEcB8nfRooALz90/mxHkLENHVbBK0B4JgzTos547Q4UN8FAEllAG5+YQ9yNHK8GEaHsDajFS5Kw1oxccfU6A2YEebDijEUmUSE339naG1LsHzbUGrkrgCYAUgQ7l1SCpM1OtK0lFIcrHcHm4OVNEgE8tJS0NDluy9yIHSpChz73dKwKs5HpadAKROzVFCesTtdIAi/FijL4zoaye5j5gKCW573tpf2xnoYETG1IB3zxofW1i5cbnx+N/79zVn8+bqKhNYAGkx+uiIiRVCxiEAmCf0rJxIRlHhlXzH44dPjrSj5zYf9ac2hkqmS4ZoZBSjSjtx+4mwFALf//NMTrYKW22882IANmypRa6YoVhKsXlGBldMLeDl3n82JT47rMasoA3kCZwEBgMvhRHtzO9a8acQ/N1fy+l7imfz0FPRaHDBaHSEL7v3105OwOVxh542X6jTYdaojrGODRcjPaDzSYbKCUoSclcUhFYuw/lp+RAL9IfQ9YQYA30rBdpps/fnefLLxYAPWv/oFnnh7HWY1VGFvQTke6F4LYAEvN7O+04yfv34Qf7thOlZUCGsANh5swNnqs3jm3ccFeS/xDCcY1tzdh5IQXV8fHm0JWgDOFw+vKIdSJtzXVejPaDzCpX6HawAAtzvU6nAJMnGMxj1hLiB82wxCqFqADZsq8cTb6zC//gikLifm1x/BE2+vw4ZNlbycv6nH7ZbgQ68+EBs2VeJP7z4u2HuJZ2aMycATq6aEnDbocLpwqtUYUbxEo5Dy0o/YH0J/RuORDqMVqQpJWG45jhue+wY/eFEY93E07gkzAPh2BdAuUDCn1kwxq6FqwLZZDVWoNfMjQd3fCCYK7h+h30s8U5ChxHdnFYY8Y6zrMMPmdEWUMWWxO7H2nSP46Ghz2OcYjmS8r+0mW38gN1zSU4SrIYrGPWEGAG6lx+Kc0At0gqVYSbC3oHzAtr0F5ShW8jOja+62QETc70NohH4v8c7Rxp6Qu5+d5JrARFA0J5eIsOVIM7442R72OYYjGe/rpRN1uHHumIjO4W4pK4znIBr3hBkAAKMzldh2zyLBlDRXr6jAmqsexK7CKbCLxNhVOAUPrFqL1Sv4CSA19fRBl6qIirT16hUVeGDVWsHeS7xz28t78c/PT4V0jM3pQpFWifHZ4U8yCCEeGQ5hMoFWr6jA3SsfSKr7+p3po3DbBWMjOodWLUen2SZIQ6lofNeCiioRQpYCeAqAGMDzlNLHB70+BsALALIBdAK4iVLa4Nn+juc4KYC/UUr/6TlmB4A8AFxe3RJKaWvE7ygOWTm9AFuPluJ20UOwSFOQQW14+IbZvAVy7r9sAtqjVI3oHvMC/DY9tT8zYU2CZ4t4k5eWguae0FJBV04bhZXTRkV87VKdBpsqm0Ap5b1y/eLyXKxRpePO6x5Bj0iG0TKKNVefl9D3taXHggyVFHJJ+AHcLLUMlAJd5sjdSYOJxnctoAEghIgBbABwKYAGAHsJIe9TSr2dU+sBvEIpfZkQchGAdQC+D6AZwHxKqZUQogZw1HNsk+e4Gyml+3h7NxGw+rUDGJOpxP1LJwhy/mtnF6IwS428NAUeef8YJubzpyOem6YQXAPIm5XTCxL6wTAc+ekKnGiOTT5+Wa4G/9ntgL7Xyvv93lalh50Cf7ltAX7w0l5cf3FZQt9jp4ti3uOf4mcXFuOeJeFLOk8fnYGfXVQMiUAB+tnjtHg2PRWvfm8izi/O4v38wfgMZgOopZSeppTaALwBYOWgfcoBfOr5eTv3OqXURinlpqbyIK8XE851mlHVHF5BSDBcWJaDB5dNwLIpuRARYHNlU+CDgoBSiud2nk6IhjYjgby0FDT19IHS4Jb8FrsTC/74Gd7e3xDxtct0GhRmKgVZ7W2qbEJ+mgKLSrORn6bAyQTXHeoy20ApIpaCnlKQhnuXlAmm1nqixYBjTb2QCuTeDeasowCc8/q9wbPNm0oAqzw/XwVAQwjRAgAhZDQh5LDnHE94zf4B4EVCyCFCyEPEz5qWEHIHIWQfIWRfW1tbEMMND62A/T0dThfq2k1wuihyNArMHafFpsPNQT9EhqPTZMMfthzHnjOdPIyUEYj89BRY7C50m4NT5jzdZsK5zr6IUg055ozTYuf9FwrSGvLW84uw9vKJEIkIZo3NhJyH8cYznIInp+cTLpRSdJpsgim11njkP0p1wiSpBHOXfT2YBz+51gBYRAg5CGARgEYADgCglJ6jlE4FUAzgFkKIznPMjZTSKQAWeP5939fFKaXPUkpnUkpnZmcL13pQq5YLpup3qs2Exet3YPNht+1bUZGPM+0mHAuzBN2bZq4PgAAFbIyhLCnX4ZUfzkaKLDi/cQ0PGUDRYEFJNlZ4ejs/df10PL5qaoxHJCzcKiqSIjAA6DLbcd5jn+AtHlZ4vqjRG5GjkQu2wgjGADQAGO31ewGAAf4LSmkTpfRqSul0AL/2bOsZvA+AY3A/7EEpbfT8bwDwGtyuppih9TR45mNWPhjuIcDlgS+dlIsrpuRBxEMgj+tQJXQjGIab0ZlKLCzNDrrys0ZvgFRMeNOLWb+1Gne8wm/Y7L9765NOZ4hb7UdeByCFiAhXRFqjNwg6eQjGAOwFUEIIGUsIkQG4HsD73jsQQrIIIdy51sKdEQRCSAEhJMXzcwaA8wFUE0IkhJAsz3YpgOUAjvLxhsKlTKfB7KJMWB0u3s9dozdALCIYl+1+CGSoZNhw43koz0+N+NzNXBFYFKqAGW533tZjLTgeZLyoRm/AuCw1Ly4gADDZHPiyth0untIO241W/Ordo9h4qLF/27lOM5b+3058fKyFl2vEIxPzNFi7bEK/vEe4iEQEmSq5YMVgZbkaLCjhP/jLETALiFLqIITcBWAr3OmcL1BKjxFCHgWwj1L6PoDFANYRQiiAnQBWew6fCOBPnu0EwHpK6RFCiArAVs/DXwxgG4DneH5vIXH1eQW4+jxhsh6qWwwo0iqHpJvVtZsglYgwKgL3TXOPBTKJKOy2dozQEBGCu147gNsuGIeJeYEN+ORRaZgyKp2365fpNDDbnGjs7sPoTGXE5/vwaAucLtrv/gHcs+JqvQFVzb1YMik34mvEI8U5GhSH0ZzHF1lqmWA9AYQWmwuqDoBSugXAlkHbHvb6+S0Ab/k47hMAQ5yJlFITgBmhDnakUqM3DJntm6wOLPm/nbhxTiEeWTEp7HPfs6QUN88vGvEdzUYKIhFBbpoi6FqAX15Syuv1ORG66hYDLwZgc2UTinPUA3SKUmRiFGYqEzoT6FynGYS45T0iJVMlE6QtpNNFBdV/AuI4LTPanGozYtGT2/HZCT3v535w2UR8f27RgG0quQSLS7PxweHmiKoI5RJxRCsIRujkpaWgudsScD+rwwmHk1+XIpcNUs2Dz76lx4I9dZ1YMTV/yASiVKfh5RrxymObq3D7y/zEUm6eNwa3zC/i5Vze/GNHLWb+fhusDuEaPTED4EEpE+NshxktPfz78pZOzvXZrGV5RT5aDVbsrQs/hfPPH1dje3VCFlDHLflpin4F1uHYeKgJ5Q9vDbuLmC80CimWTc5FNg+6T1XNPVBIxFhekTfktTKdBmfaTYI+fGJJh8kWcQYQx9LJebjSy4XGF9V6IxRSUUSVyoFgBsBDZr8kNL8GoLbViG9Od/icCV4yMQcpUjE2hVkU5nRRbNhxCvsiMCCM0MlPT4G+1xJw5VbTYgAh/Ku0/uOmGbhu5ujAOwbgogk6HHjoUp8aRbPGZmL51LyotRmNNh1Ga8RFYBy9FjuONfXwvtqraTEI3nKVGQAPcokYGoUEHTz78t7cdw43v7DH52tKmQQXTczBtuP6sLI6Wg3uhxCrAYguN80dgy0/X+CzQMabar0BJTq1IH5ch9MVUSYQd6y/eoZFpdl46vrpvM2S440Oo423xIkth5txxV+/RKuBv8mj3enC6XYjSgWuH2EGwIsstZx3A1CjN2B8ttqvUueDSydg6y8XQhTGQ6KJ1QDEhPz0FJToNAHv2Um9MaIeAP74pEqP8ke24nR7+EHaZ784jSv++gXMNofffSilsNgTbwVgsTthsDqQFWEVMId3R0G+qGs3we6kglUAczAD4MUlE3NQHkRqXyi4l3H+b+LoTGXYVX5NnkAkqwGILkarAy99dWbYWoAesx0tvRZBlvB5aQrYHC7URJCls6myCRKxaNg2k9c98zXueu1g2NeIVwgBnrp+Gi4p1wXeOQi4VRKfGk0KqRi3XTAW00Zn8HZOXzAD4MWvryjHTxeP5+18vRY7mnosAZdxX55sxy0v7IEtxCI0bsYRjU5gjG9xOil+u6kKX9X6b85CQXHfZWWCKDgW56hBiDsVNBxOtxlxrKkXK6YODf56k5OqSMgKYblEjJXTRmFCLj+TPW4lwWc18OhMJR5aXo6xWfxUkPuDGYBB8CkFweVRB5oF2p0ufF7Thi9OhiZ2d8v8Ipx4bClSFcI1C2cMJTVFAqVM3L8C80W6UobVFxYLItymkIpRpFWF/XDefNjdVvKKAAagTKdBfad5WDfRSKTVYMHu0x3os/Hj3uJcQHxWA5/rNEfF/cYMgBfP7jyFSY9s5a3MflJ+Kt65cz5mFmUOu9/5xVlIS5H2fzFDQSEVsyKwKEMIQV6AYrDTbUa08RgUHEwk3cE2VTZhdlFmwJUjF79ItIKwL2ra8d1nv4G+N3AtRzCoZGL88ZqpvHYUvOWFPbj7v4d4O58/2NTRC7lEDLPNie4+Oy/ZDwqpGOcVBvbhySQiLJuci02VTbDYnUELja3bchyFWiVunBNZX1NG6OSnp6Cpx/8DZO07R2BzuvDunecLcv0rK0bhbKcp5ONcLoo7Fo4L6vPtXXRWMZo/OYtYw83UI5WC5iCE8JKWy2GxO1HXYRogzyEUbAXgBd+1AP/dW4+dNcG5dVZU5MNkc2L7ieCLut4+0IgjDawRTCzIT0vpF+IbDKXUreIoYA73FVPzcOfi4pCPE4kIrp05GhdPDBwAHaNV4ccLxwmeix5tOow2yCQiqOX8zX9r9AYcOtfNy7lqW41w0ehIiDMD4AU3I+BL2OnJrdX9PQACMWdsJi6ekBO0zrzV4US70cpqAGLEA8sm4LM1i32+1m60octsFyQFdOB1rCG5mSileGNPPVoNwbk+xCKCtZdPTKjZP+C+P1kqGa+u0/+35Tgeeo8fQePB8vFCwgyAF1k8BnM6jFa0G21B30SJWIR/3ToLi4P0I7Z43A+RytkywiNTJfM7g4xGExi704V56z7FC1+dCfqYo429ePCdI/jsePCrzD6bM+HajXaY+KsC5tCq+GsoVa03QCYWoUgbuVBdIFgMwAtdqgLXzxrNS1oll6MdqhXvMdvR02dHYYCbz2WgsBVAbGju6cNLu+pwzXkF/QqdHNUtws/gpGIRxmWp+1sGBsOmw02QiAiWTg5e4vnlr+vw+IcnUPnIEqSlSMMYafyxZkkZzDxlAHFkeTWUinRlsXxK/rDFo3zCDIAXaSlS3lrhhTMLpJRixd+/RKlOg+dvmTnsvn12dyUjMwCxwWR14pnPT2NCrmaIAbhkog7pSilvlab+KNGpUdkQnN/Z5aL44HAzFpRkhVR4WNafCWQImM02UhAiNVerlsHmcMFodUCjiMxQTilIw5QC/sfoC+YCGoTLRXnJDz7TbkJaihQ5Iag2EkKwpFyHz2ta0dM3fJPpiybosO83lwpeKMLwTb6n+tpXLUChVomrzysQPD23TKfBuc4+mKyB8/QPnutCY3dfyJklJTzKT8cDlFK8X9mEM+2hZ1ANh1blcR9HGD/s8ySCdJuFaTAzGGYABnH5X7/AL/8befn7IyvK8dm9i0J+CCyvyIfdSRO6HV8ioJRJkJYiHVILQCnFuwcbeJWA9gdXYX6yNXCe/qFzPVBIRbg0RPmDUekpUMnEIbma4hmTzYmfv34Qn1Tx+/06vzgLL/9wdsQy3cdbevGDl/Zib10XTyMbHmYABpGhlPFS0k0ICSvQVFGQhtGZKdgUoCjssc1VWLfleLjDY/BAXppiSGOYph4L7v5vJXZUh1bVHQ7nFWbgyWumoiAjsBvwtgvGYvevLgnZPUEIQWlu4jSH4QK13IydL3LTFFhUmg1VhKmlnKGNVuotMwCD0KplESuCthosuPfNShxtDD17ghCCFVPzsau2HT1m/26gr2rbcaqN32UsIzRGpacMcdX1f4GjkMOdrZHj2pmj+7PX/MHJm4QbxL3n0lLcc2lZWMfGG1yKN19FYBw2hwsfHW1BbWtkhrJab0CKVByUUecDZgAGkaWWR6zqd7zZgLcPNMAYhG/WFzfPK8K2exYhTen/C9vU3YdRTAU0pvzjphl466fzB2zjZsqlPDUcD0RtqxFfnvQvSgcAv33/GO78z/6wda4WlGRj9tjECABzK4BARjNUKCh+8u/9+OhoZK4lt4S4Oix5+HBgBmAQWpUMBosjolZ4NRGmAeamKVA0THDXaHWg1+JAHssAiikyydCvT43eAF2qfFjjzSdP76jFvf/zrxljd7qw6XAzxCJR2EHpPpsTn1Tpca5T+LiG0HAKunyvALiGUpEWkVbrDVEpAONgBmAQc8dr8ctLSuCKoLtbtd6AbI08Ij2hGr0Bq/9zwKdgFSdBwIrAYsvRxh78/PWDAwK+NVH+ApfpNND3Wv1mjew61YFOky2g9PNwGKx2/OiVfdh2XB/2OeKFyybl4u2fzkc2zysAgJ+GUv++bQ5+wqMkfSBYHcAgZhVlYlaE+c7uh0BknXxEBPjgSDNmFmXgB+ePHfCazenClFFpGKNlKaCxxGR14P3KJlw3czQKMtyFey/cMits1184cJlANXqjTzfN5somaOQSLCrLDvsa2Wo5MpTSiBrQxAsZKhlmCNTmUquSRVwNHI3YkTdsBTAIp4ui1WAJKrfaF5yfNdLOYsU5GkzMS/XZMH5Sfho2/ewCTEswjZaRBleE1+QlCpeTqsA4H03WhYJbbfjK0rE6nPjoWAuWTMqFXBKcxpQvCCEo1WkSojnMp8f12CpQirVWHVkG4d66Try2u5735vLDwQzAIM51mjH7D5+G/SEhhOD9uy7Ary6fGPFYlk/Nw4H67qjklDNCR5eqACFAk6cW4HBDNzZsr0WvZfgiPj7JT1NALZf4zNN3OCl+ung8bpgduVRxWa4GNS0GXhsmxYJ/fXkGz+48Lci57186ARtuPC/s4zceasS6D49DHKUAMMAMwBC0PLV346MKdMVUd9XmB4NqAn6/uQo/fGlvxOdnRIZMIkKWWt5fC/B5dRue3FoNSRS/wIQQvHrbbPzikpIhr6nkEty5uJgXCYdSnQYGqwPNw/RAGAl0GG3QCuQCGp+tRnFO+Ku/mhYjynSaqDZ4YgZgEGq5BDKJCO1hKoK++nUdbnp+Ny/LuEKtEldMzYN6UMvH4y29/dkMjNhSptP0p+xV6w0YnZkybKN1IZhemDEkrbHP5sTmw028tT1cNjkX2+5ZCF3qyE486DDZeM8A4jjTbsLLu+rCigFRSt0ZQCwGEFsIIchShe/L23e2C2faTbwp+W343nlDOn41d1v6tWgYseXft8/BuqunAIDgTWD8Ud9hxtM7atHlNSnYXt2Ku147iIP1/EgKaNVyFOdoouqe4BuXi6LTZOW9CpjjaGMPHnn/2ICYULC0Gqzo6bNH/fPDDIAPtOrwtb2rWyLPABqMzeFCfYc7DkApRVNPH/J5kKxm8IfN4cLpNlNUU0A5GrrM+ONH1ahq7u3ftqmyCVlqOeaM0/J2nfcONuLt/Q28nS/adPfZ4aL81wBwfNtQKvRnx6m28OTjI4WlgfrgRwvHQeGjyCcQdqf7IRBJyp0vfvzqPjR1W7D17oXoMtthsbtYEVicsP1EK57eUYuHlpeDkOh/gQH0y1FXtxhwfnEWjFYHPjvRihtmF/I6Y3/7QAO6zDasmlHA2zmjSVqKFF89eBFUQXbdC5X+hlJheA/mj89C5cNLoJBFd07ODIAPrgyzGfPZDhNsThfvy7gLJ+Tg4Y3HUKM3IFUhxZJyHSZG2VfI8I3Z5sTeui5IxSJUPboUrhhkyWSpZchUyfrTNLdV6WF1uLA8guIvX5TqNPjP7rNwuuiIdAWJRQSjBJw4ccHlcONz0aoe94a5gHzQbbbhcEN3yClvNgfFBcVZKM+PrAZgMMsm50FE3EU9uWkKPHvzTMwvzuL1GozwyOvvC9AHqVgUUb59uLjz9NX9tQC7z3QiP02B8wozeL1OmU4Di901YiUhjjX1YMP22oC9NsIlXSkDIQjLffz4hydi4l5jBsAH/917Dlf+/SuYQsygKM9Pxb9vn4MJufwagGyNHPPGa7HpcPOIz8NONLhYzH1vHcaG7bUxG0eZToO6dhMopfh/V03Gxrsu4F1QjMtQGanS0PvPduHJrdWwC1RoJRYRbL93MX68KDQpB5eL4pWv63AkDPXgSAnKABBClhJCqgkhtYSQB328PoYQ8ikh5DAhZAchpMBr+35CyCFCyDFCyE+8jplBCDniOedfSTSTXwOg7fflhWbJXS7hHs4rpubjTLsJt764F+c//hkzBHFCtkYOiYig02SLafP0ey8rw55fXwJCCAghETcm8UVJjhqEAA1doWe5xAPtRhsIcff8EIqiLFXIPQEau/tgtjmjLgMBBGEACCFiABsALANQDuAGQkj5oN3WA3iFUjoVwKMA1nm2NwOYTymdBmAOgAcJIZyD/R8A7gBQ4vm3NML3whvfRvND8+Ute+oLPLLxqBBDwrIpefjFReNxrLoRTV1mXPbYFmw8OHIzMhKFzZWN0Nj7QKgLB46di9k92X5cjyv+8CHGPrAZc3/1niDjUMklOPLby3DbBWMD7xyHdBityFTKBI1ffHikGf/+5mxIx3Cxm1gkEARjqmYDqKWUngYAQsgbAFYCqPLapxzA3Z6ftwN4DwAopd5PUDk8BocQkgcglVL6tef3VwB8B8CHYb8THgknmGOxO1HbZsRlk0JruRcsO07o8c5HB/HXt9dhVkMV9haU44HutQAWYOX0kZmVMdLZeLAB61/9Ahu874kl+veEG8cTURiHOsKOV7GkwyhcERjHlqMtONbYg5vmjgm8swfOpVbCc/p4MATjAhoF4JzX7w2ebd5UAljl+fkqABpCiBYACCGjCSGHPed4glLa5Dnee4ri65zwHH8HIWQfIWRfAAWcMQAAFa9JREFUW5vwbfaA8FxAp9tMcLqoYJV8GzZV4om312F+/RFIXU7Mrz+CJ95ehw2bKgW5HiMw8XJPojmOnTVt+Mmr+2FzRE+wjC86BCwC49CqZCHXAfTZnBifrUJqiO06+SAYA+BrvTTYAb0GwCJCyEEAiwA0AnAAAKX0nMc1VAzgFkKILshzwnP8s5TSmZTSmdnZ/ObX+yNbLcf6ayswN4QiGqGXcbVmilkNVQO2zWqoQq2ZxQJiRbzck2iOo9Nkw0fHWlDXMfLakb72o7l45uYZgl5Dq5Kh1+IIyUDeu6QM2+5ZJOCo/BOMAWgA4C0nWABggEYxpbSJUno1pXQ6gF97tvUM3gfAMQALPOf0XpsOOWcskUlEuGZGwbBduQZTrTdAKiYoEkijv1hJsLdgYOhlb0E5ipVxEztPOuLlnkRzHJybYiRKQ0vFIsFn2Zz3INRagFjlwARjAPYCKCGEjCWEyABcD+B97x0IIVmEEO5cawG84NleQAhJ8fycAeB8ANWU0mYABkLIXE/2z80ANvLyjnjiaGMPjjQEn9VRUZCOHy0Y57NNIB+sXlGBB1atxa7CKbCLxNhVOAUPrFqL1SsqBLkeIzDxck+iOY7x2WqICHzKT8czNocLD713FLtPdwh6nVDlIM60m3DV019h/9lOIYfll4ARHUqpgxByF4CtAMQAXqCUHiOEPApgH6X0fQCLAawjhFAAOwGs9hw+EcCfPNsJgPWU0iOe134K4CUAKXAHf+MiAMzx8MajSJGJ8Z/b5wa1/9LJuVg6OVew8biDeQvw2/RU1JopipUEa1ZUsABwDImXexLNcSikYhRlqUZcLUCnyYZXvzmLCXkaXvWRBrO4LBtVj14WtCLsieZeHKzvhkwc/QJCIEgpCErpFgBbBm172OvntwC85eO4TwBM9XPOfQAmhzLYaKJVy4OueLQ5XGg3WpGXphB0KbdyegF74McZ8XJPojmO8wozYLHzIzMdLbgZudBB4FArwav1BhCCiPoIRAKrBPZDlloWdIPnY009mP/4Z/ikauQ3zWYwArH+2gr8/Xvhd76KBdx3OUvgNFC704Xfb67C9urWoPav0RswJlOJFIEE6gLBDIAftCo5Ok22oKp7T+pjI+XKYDCCg0vp1qqFXQFIRASvfH0W3wQZa6huMfSrucYCZgD8oFXL4HTRoISjqvUGKKQijM5URmFkDEZsaTNYsfLvX2Lz4bhJ3AuIyeqAWEQELwQjhATdHJ5Sigm5qZgnYEwiECO3rE9gLi3XoVSngVIeeGlWozegZIR3S2IwgiVDKcXxZgOONPZg+dTwpNOjzffnFeHGOWMQjWxLtwEInAVECImoiTwfMAPgh4IMJQoygpvRV7cYsKAkOkVqDEaskYhFGJetGnGpoHyro/pDq5IHFT90uWjUxuQP5gLyg9nmwJYjzahrH77ikVKKX18xEd+dNXrY/RiMRKIsV4MaT+xrJPC3T0/i75+djMq1tGpZUFlSf/qkGgv/uF1QFeFAsBWAH0xWJ+78zwE8unLSsBXBhBCsnOZTxojBSFhKdRpsPNQEg8UOTQw0bEJl23E90gWUgfZm/TUVQc3sq1uMUEhFMV0FsBWAHzKUUhASWBK6ttWAA/VdMbXiDEa0Oa8wA8sm58JkHRn1AO1RUALlCPaBXqOPbQYQwAyAXyRiETKUgYM5L+86i1v+tScqwSUGI16YN16Lf9w0A7lpilgPJSg6TNb+pu1Cc+hcN+567QBaeix+9zHbHKjvNPPePzxUmAEYBq0qcDpXtd6A0lxNzMScGIxYMhJkoc02Byx2V3+fD6HpMtuw+XAzmnr8d06Ll9ohZgCGQauWocPkfwVAKcVJvQGlMWjkwGDEmltf3IMfvrQ31sMIiMHiQH6aArrU6KxWslRcPxH/k0e1QoJb5o3B5FH89g8PFRYEHobff2cypGL/NrLNaEWX2R5zK85gxIJstRw7aqLTpCkSdKkK7Fp7cdSux8UahnMfj89W43crYy+FxlYAw1Cco8GYYfT9a1rcy7hY+/EYjFhQqtOgzWANWfs+0cn0uJqGqwVo6u6Dwxl79xkzAMNwoqUX//ryDOx+btT0wnT89465mDo6PcojYzBiD9f+NN6bw3x8rAU/eHEPus3RMVQKqRijM1OG3efqp3fh/rcPR2U8w8EMwDDsq+vCY5ur/M5wVHIJ5ozTjuhG2QxGuHAr33g3ACdbjdhe3QaFNHqKm1/cfxFWX1js87Uesx0tvZa4cB0zAzAMWQG6+7yxp17wDkMMRryiS5XjjoXjMDEvtoHMQHQYbVDLJVE1AMNR0+o2mPHgOmYGYBg46Vhf0XxKKR7bXIUtR5qjPSwGIy4ghOBXl0/ErKLMWA9lWDpM1n6/fLT4x45TuOfNQz5f41ZMnAstljADMAza/mDO0BVAY3cfTDZnXNxEBiNW2Bwu1OgNoDR+K+E7olgFzFHfacLOmnafr9W0GKCWS5AfB0V0zAAMw3ArAM6Kx8MyjsGIFa/vqceSv+xEmyG4JuixIFsjj7qbSquSo8vsu6HUldNG4ZEV5XFRPMqil8OQqpBg530XIid1aAl5tScFNNZaHgxGLOECmdV6A3KiVGgVKn/57rSoXzNT9W1DqYxB7qcZYzIwY0xG1MfkC7YCGAZCCAq1Sp/Bo1NtRuSmKpCWEv9KiAyGUHBV8NUjrDeA0PQXgw1yHxssdnx5sh0GS+BOg9GAGYAAvHOgAW/uPTdk+x9XTcX7Pzs/BiNiMOIHrVqOLLU8blNBe8x2LP2/nfjoaHSTNUalp2BiXirszoEuoMMNPbjpX7tRea4nquPxB3MBBeC9Q03o6bPjukENX0QighxNfC55GYxoUparRnWcNodpM1pxosUAa5RF62YWZeLDXywYsv3bDKD40A9jBiAAWSoZTrcN/HA3dJmxYXstbrtgLIpzWAyAkdzcubgYrjjNAuL0eKIlBR2IGr0BGUopsuNkPMwFFAB3g+eBWUBHG3vx+p5zMNtGRjMMBkNIzi/Oitue2JweT7TTQCmluPrpr/DiV2cGbK9uMaBUFz/y8cwABCBTJUef3QmzzdG/rUZvACFAcU58LOMYjFhidTixo7o1YP/sWMCtALSq6M64CSGo6zDjlJf3wC0fb0RZHNUOMQMQgG+lXb9dBVTrDRidoYRSxjxoDIbN4cKtL+7FB3FYFZ+ulGF2USYylNHP1vPVUOr1O+bi1vlFUR+LP9gTLABXVuTjyor8AamgNZ5lHIPBADQKKfLTFDgZh5lAKyrysaIiPybXHuw+JoRg8qi0mIzFH2wFEACFVDzg4e9yUbgoxcQ8ZgAYDI7SXE3cZgLFCq1ajnavOoCvT3Xgrf0NcSWbwVYAATBY7PjzJzVYUp6LeeO1EIkIPr13cVzdRAYj1pTpNNhV2wGH0wXJMF30os3tL+9DaooEf74u+tXA0wrSIfIK9v5v/zl8VduOa2YURH0s/mAGIAASkQgvflWHbI0c88Zr+7fHSxSfwYgHSnUa2JwunO00Y3x2/CRHnG43YmJubOSqf7Rw3IDfa/Tx5zqOH1Mdp6TIxFDKxP2+vOe/OI3bX97HVgAMhhcXTcjBlp8vQGGmMtZDGUAslEB94XR5MoCYARh5uIM5bl/e7jOdqOswsRUAg+FFhkqG8vxUSOPI/WNzuNDTZ496CijHrtp2zFv3KY439+JcpxlWh2tkrgAIIUsJIdWEkFpCyIM+Xh9DCPmUEHKYELKDEFLg2T6NEPI1IeSY57Xveh3zEiHkDCHkkOdf9J10QaJVyfsLSk7qDXFnxRmMeOCjo834376hulmxosscmyIwDqlEhOYeC9oMVtS2ugPk8dY/JKABIISIAWwAsAxAOYAbCCHlg3ZbD+AVSulUAI8CWOfZbgZwM6V0EoClAP6PEOLdQf0+Suk0zz/f7XPigCy1HFaHC302J852mlGiix8fJ4MRL7xzoBH//PxUrIcxgBUV+TGbdXs3lLp4Yg72/voSlMdZ+8xggsCzAdRSSk8DACHkDQArAVR57VMO4G7Pz9sBvAcAlNIabgdKaRMhpBVANoDuyIcePZ67eQYIITjS0ANKWRMYBsMXZbkafHqiFVaHE3JJ7Pvv6lIV+NsN02N2fe+GUoQQZGviQ//Hm2BcQKMAeK/rGjzbvKkEsMrz81UANIQQrfcOhJDZAGQAvKcIf/C4hv5CCPH51yGE3EEI2UcI2dfW9v/bO/cYqao7jn9+7LLiLs9lkW55CUJLsZQCi0VEJFURiYhKa2hMitq0JYW0mNAAgSAhaQiY+octpbGFFgVboshDQZG0pEYoyvJcXsIuICyLsIBlQVp57K9/3DOb2WFmd9jH3DOZ3ye5uWfOPefud39zzv3N/d1zz6lMQm7TE4n3X6+u5ns98+nrmRc3DB/o07kNN6qVo5V+TAkR9kCNtq2yaZklnLt8lfkbDnq5fngyDiDe085Yy04DHhCRXcADwCmgZvIcESkEXgeeU9XIvKwzgb7AECAfmB7vj6vqq6papKpFnTqFM+HU1rJz/GLFDu66ozUrf34vPQvyQtFhGD4TuTP2ZW2AJR8d49svbqQqpMVXRIQnB3bhzo65LPnoGCWn/FgDIJpkHEA5ED0ZflegIrqAqlao6lOqOhCY5fIuAohIW2A9MFtVt0XVOa0BXwF/IQg1eUnlpa/YUPI5Z6v8XffUMMKmZ0Ee2S2Ez85fCVsKEMwE+r9rN2hzW3ivOy38wQAG9ejA9Wr1MnScjAPYDvQRkZ4ikgNMANZFFxCRAhGJnGsmsNTl5wCrCR4QvxlTp9DtBXgC2NeYf6Q5iQwje+jlf7Hw/UMhqzEMP8nJbsGO2Q/zywf7hC0FCGYC7dg6J/Qh24fccpm+DQGFJB4Cq+p1EZkCbASygKWqul9E5gHFqroOGAnMFxEFPgQmu+pPAyOAjiLyrMt71o34WSEinQhCTLuBSU33bzUt0cPIWreyl6cNIxHtQph1MxHnL18N7R2ACLPXlLB82wmyWgi9OvkXOk7qaqaqG4ANMXlzotJvAW/FqbccWJ7gnN+/JaUhEu0AfLyNMwxf+OTYBZb9+zgLx3+HvBBDLxCEgMJ+C7iVGw31jc5tak0q6Qv+vLbnMVsOV5J79Qqi1fxm5Ses3VUetiTD8JKNJRVsLi6j/5z3GTVvfYP6ytpd5Yyat55eM95t1DnOnKpky+HKBp+jsazdVc76rYcRreb6fy76ed1Q1bTZBg8erKlmzc6TOvyFN3RL9/56tUWWbuneX4e/8Iau2Xky5VoMw2fW7Dyp901tXF9piv7mQ5/1QUM0BOH6m66pFtCuh0Xv7GHBqvkMO1ECwLATJSxYNZ+57dsybqA/07oaRtgsemcPC9+O31f++WklByqqapX/VmFbXnEvav30tWKOn/uSsxXnWBynv03Jvo3fb679lvHwPgW8OPZuAMYv3krVf4PhnonOkco+my7XDXMA9VB6RRlSfqBW3pDyA5ResdlADSOauvrKwx1u59qN6lrHuuXfXpPukZ9Lyyyh9MyluOf4QnIYGjMFS2G7VjXpXgV5fOnW7U50jlT22XS5bpgDqIfeucL2rv1qPDnA9q796J1rs4EaRjR19ZVfP9K3zrqzHwumFxtVtj7uOfrkCX94ZnDC+i/9cEBNOtE5Utln0+W6YQ+B62Hy2AFMHz+Trd37c61FFlu792f6+JlMHjug/sqGkUE0RV/x5RyNxQcNyWB3APUQxOvuZ277tpReUXrnCtPGDvAqjmcYPtAUfcWXczQWHzQkg2garWxVVFSkxcXFYcswDMNIK0Rkh6oWxeZbCMgwDCNDMQdgGIaRoZgDMAzDyFDMARiGYWQo5gAMwzAylLQaBSQilcBnYeuogwLgXNgikiRdtJrOpiVddEL6aE0HnT1U9aYlFdPKAfiOiBTHG2rlI+mi1XQ2LemiE9JHa7rojIeFgAzDMDIUcwCGYRgZijmApuXVsAXcAumi1XQ2LemiE9JHa7rovAl7BmAYhpGh2B2AYRhGhmIOwDAMI0MxB3CLiEg3EdksIgdFZL+I/CpOmZEiclFEdrttThhanZbjIlLidNw0laoEvCIipSKyV0QGhaDxm1G22i0iVSIyNaZMKDYVkaUiclZE9kXl5YvIJhE54vYdEtSd6MocEZGJIeh8SUQOue91tYi0T1C3zjaSIq1zReRU1Pc7JkHd0SLyqWuvM0LQuTJK43ER2Z2gbkpt2mDiLRRsW+INKAQGuXQb4DDQL6bMSODdsLU6LceBgjqOjwHeAwQYCnwcst4s4HOCF1dCtykwAhgE7IvKWwjMcOkZwII49fKBo27fwaU7pFjnKCDbpRfE05lMG0mR1rnAtCTaRhnQC8gB9sT2vebWGXP8t8AcH2za0M3uAG4RVT2tqjtd+hJwEOgSrqpGMQ54TQO2Ae1FpDBEPQ8CZarqxRvfqvohcCEmexywzKWXAU/EqfoIsElVL6jqF8AmYHQqdarqB6p63X3cBnixGkkCmybDPUCpqh5V1avA3wm+i2ahLp0iIsDTwN+a6++nAnMAjUBE7gQGAh/HOXyviOwRkfdE5O6UCquNAh+IyA4R+Vmc412Ak1GfywnXoU0gcafyxaadVfU0BD8IgDvilPHNrs8T3OnFo742kiqmuHDV0gRhNZ9sej9wRlWPJDjui03rxBxAAxGR1sAqYKqqVsUc3kkQwhgA/A5Yk2p9UdynqoOAR4HJIjIi5ni8VapDGRssIjnA48CbcQ77ZNNk8Mmus4DrwIoEReprI6lgMXAX8F3gNEF4JRZvbAr8iLp//ftg03oxB9AARKQlwcV/haq+HXtcVatU9bJLbwBaikhBimVGtFS4/VlgNcFtdDTlQLeoz12BitSou4lHgZ2qeib2gE82Bc5EwmRufzZOGS/s6h4+PwY8oy44HUsSbaTZUdUzqnpDVauBPyXQ4ItNs4GngJWJyvhg02QwB3CLuNjfEuCgqr6coMzXXDlE5B4CO59PncoaHXki0iaSJngouC+m2Drgx2400FDgYiS8EQIJf1X5YlPHOiAyqmcisDZOmY3AKBHp4MIZo1xeyhCR0cB04HFVvZKgTDJtpNmJee70ZAIN24E+ItLT3S1OIPguUs1DwCFVLY930BebJkXYT6HTbQOGE9x27gV2u20MMAmY5MpMAfYTjFLYBgwLSWsvp2GP0zPL5UdrFWARweiKEqAoJK25BBf0dlF5oduUwCGdBq4R/AL9CdAR+AdwxO3zXdki4M9RdZ8HSt32XAg6Swli5pF2+kdX9uvAhrraSAhaX3ftby/BRb0wVqv7PIZg5F1Zc2uNp9Pl/zXSLqPKhmrThm42FYRhGEaGYiEgwzCMDMUcgGEYRoZiDsAwDCNDMQdgGIaRoZgDMAzDyFDMARiGYWQo5gAMwzAylP8DgIh6AcUqKuIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot of k values and scores\n",
    "plt.plot(range(1,20),scores,marker='o',markerfacecolor='r',linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=7, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optimum k values is 7\n",
    "final_model=KNeighborsClassifier(n_neighbors=7,metric='euclidean')\n",
    "\n",
    "final_model.fit(scaled_X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B', 'B', 'B', 'M', 'B', 'M', 'B', 'M', 'B', 'B', 'B', 'M', 'B',\n",
       "       'M', 'B', 'M', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'M', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'M', 'M',\n",
       "       'M', 'M', 'M', 'B', 'B', 'B', 'M', 'M', 'B', 'M', 'B', 'B', 'M',\n",
       "       'M', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'M', 'B', 'B',\n",
       "       'M', 'B', 'B', 'M', 'M', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'M',\n",
       "       'B', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'M', 'M', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'M', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'M', 'M', 'M', 'B', 'B',\n",
       "       'M', 'M', 'M', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'B', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'M',\n",
       "       'B', 'M', 'B', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'B', 'M', 'M',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'M', 'B',\n",
       "       'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'M', 'B', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'M', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'M', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'M',\n",
       "       'M', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'B', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'M',\n",
       "       'M', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'M', 'M', 'B',\n",
       "       'M', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'M', 'B', 'M',\n",
       "       'B', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'B',\n",
       "       'M', 'B', 'M', 'B', 'M', 'B', 'M', 'M', 'B', 'B', 'B', 'B', 'M',\n",
       "       'B', 'B', 'M', 'M', 'B', 'B', 'M', 'B', 'M', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'M', 'M', 'B', 'M',\n",
       "       'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'M', 'M', 'B', 'B',\n",
       "       'B', 'B', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'B', 'B',\n",
       "       'B', 'M', 'B', 'B', 'B', 'M', 'M', 'M', 'B', 'B', 'M', 'M', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'M', 'M', 'M', 'B',\n",
       "       'M', 'B', 'B', 'M', 'M', 'B', 'M', 'B'], dtype=object)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction on trainoiing data \n",
    "final_train_pred=final_model.predict(scaled_X_train)\n",
    "final_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2817de0bd48>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "sns.heatmap(confusion_matrix(y_train,final_train_pred),annot=True,fmt='d',center=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.97      1.00      0.99       257\n",
      "           M       1.00      0.95      0.97       141\n",
      "\n",
      "    accuracy                           0.98       398\n",
      "   macro avg       0.99      0.98      0.98       398\n",
      "weighted avg       0.98      0.98      0.98       398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "# Precision-->ppv-->out of the positive predicted values,how many truly positive\n",
    "print(classification_report(y_train,final_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B', 'B', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'M', 'B', 'M',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'M',\n",
       "       'M', 'B', 'B', 'B', 'M', 'B', 'B', 'M', 'M', 'B', 'M', 'M', 'M',\n",
       "       'M', 'B', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'M',\n",
       "       'B', 'M', 'M', 'M', 'B', 'M', 'B', 'B', 'B', 'M', 'B', 'M', 'M',\n",
       "       'M', 'M', 'B', 'M', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'M', 'M', 'B', 'B',\n",
       "       'B', 'M', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'B', 'M', 'B', 'M',\n",
       "       'M', 'B', 'M', 'B', 'M', 'B', 'M', 'B', 'M', 'B', 'B', 'B', 'B',\n",
       "       'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'M',\n",
       "       'B', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'M', 'M', 'B', 'B', 'B',\n",
       "       'M', 'M', 'M', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'M', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'B', 'B',\n",
       "       'M', 'B'], dtype=object)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction on test data\n",
    "final_test_pred=final_model.predict(scaled_X_test)\n",
    "final_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2817deb7808>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compare actual alues of tst data(y_test)and final_test_pred(model preddicted values)\n",
    "# confusion_matrix(actualvalues,predicted values)\n",
    "sns.heatmap(confusion_matrix(y_test,final_test_pred),annot=True,fmt='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.92      1.00      0.96       100\n",
      "           M       1.00      0.87      0.93        71\n",
      "\n",
      "    accuracy                           0.95       171\n",
      "   macro avg       0.96      0.94      0.94       171\n",
      "weighted avg       0.95      0.95      0.95       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report of test data\n",
    "print(classification_report(y_test,final_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    " ## http://tiny.cc/kFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the prob of a tumor being bening an bening or malingnent\n",
    "# predict -->givre you the predicted value()\n",
    "# predict_proba-->gives you the probability associated with b and probability a\n",
    "#syntax: objectname.predict_proba(input values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>169</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>171 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1\n",
       "0    1.000000  0.000000\n",
       "1    1.000000  0.000000\n",
       "2    0.428571  0.571429\n",
       "3    1.000000  0.000000\n",
       "4    1.000000  0.000000\n",
       "..        ...       ...\n",
       "166  1.000000  0.000000\n",
       "167  0.857143  0.142857\n",
       "168  1.000000  0.000000\n",
       "169  0.000000  1.000000\n",
       "170  1.000000  0.000000\n",
       "\n",
       "[171 rows x 2 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_prob=final_model.predict_proba(scaled_X_test)\n",
    "y_test_prob=pd.DataFrame(y_test_prob)\n",
    "y_test_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "528    B\n",
       "291    B\n",
       "467    M\n",
       "108    B\n",
       "340    B\n",
       "      ..\n",
       "2      B\n",
       "25     M\n",
       "52     B\n",
       "386    M\n",
       "476    B\n",
       "Name: diagnosis, Length: 171, dtype: object"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "## roc curve\n",
    "from sklearn.metrics import roc_auc_score,roc_curve\n",
    "m_prob=final_model.predict_proba(scaled_X_test)[:,1]\n",
    "fpr,tpr,threshold = roc_curve(y_test,m_prob,pos_label='M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.61971831, 0.73239437, 0.87323944, 0.94366197,\n",
       "       0.97183099, 1.        ])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.  , 0.  , 0.  , 0.06, 0.16, 1.  ])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.        , 1.        , 0.85714286, 0.57142857, 0.28571429,\n",
       "       0.14285714, 0.        ])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2817ef4c2c8>]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAStklEQVR4nO3df5BdZX3H8fd3f/HLBCwJJCSBQA2QiCLMFrBOKxbqAB1J66iTdJhWizL+gE4Hp1M6ttTBaTvVWqd2UjXTOqiDIOoMZjQOnVqsHRXKIsivkE4ENFtCWRBIEEN2s9/+ce8md2/u7j1J7u7NPvt+zezk/Hjuud9n7+4nz33OuXsiM5EkzX093S5AktQZBrokFcJAl6RCGOiSVAgDXZIK0detJ160aFGuXLmyW08vSXPSfffd92xmLm61r2uBvnLlSoaGhrr19JI0J0XET6fa55SLJBXCQJekQhjoklQIA12SCmGgS1Ih2gZ6RHw+Ip6JiIen2B8R8emI2BYRD0bE+Z0vU5LUTpUR+s3AZdPsvxxYVf+6BvjM4ZclSTpYba9Dz8zvRcTKaZqsBb6Ytb/De3dEnBARSzNzR4dqlKRZNT6ejI6PM7o3Gds7zp6944ztTUb3jte/ctK/E/tatRsbH2fP2P5jje4d55LVJ3PuihM6XncnPli0DNjesD5c33ZAoEfENdRG8Zx66qkdeGpJR7KJYBxrEYB76uE2sTw2sX98nNGxyWE4Nj758aNj44yOTxyrtn3SMZqOPbq3RQ3jWQ/a+vHHxveF+N7xmb1PxMnHH33EBnq02Nbyu5GZG4GNAIODg95ZQ6ooMw8Iw7HxcUbHJkaSDcv1AJxqVFkbcU5eHtvbPPJsDNr6tonQa1geG5/8mObHj81wMPb3Bv29PfT1BAN9PbXl+rb+nh76+4K+nh4Gens4qr+H447qq+2baNOw3NcbDDQ+ftK+HgZ6a8fq75u83N8T9PfVaujv7WGgYXniGLXH15Z7e4KIVrF5+DoR6MPAiob15cBTHTiu1HGZuX+01xCGzeE19VvsyW+dW4XZxMhvX+A2BWBjgDYutx617j/mTOqfCKjeqAdSLQz7eyaH5EA9sI5rCsXpwnBfqDUGYO/k5f2Pbx22zTX09QZ9MxiMc1UnAn0TcG1E3AZcCLzo/Hn5JoKx9Vva1gE4ZWA2jfb2tBj57X+eNmG675gNYdowlzm6d2aDcf/I7MCwmzR6rP97zEBttNffGGaNI8u+/WE4eeTXKkynD8MpR58GYzHaBnpE3ApcDCyKiGHgr4B+gMz8LLAZuALYBrwMvGemii1RZm2+bso5wJbzfJNHe61GftO9dZ48+pwYAdYCsNVb+X2Pa5rLnEl9B4zcJo/Omt8GTwRj8yhw3+NahOHE4/tbhGFzCE8Kw4nRa9Pb+v5eg1HdVeUql/Vt9ifwoY5VVJjx8WT4+V/y6I6dbNmxk8ee3smWHbt49qVX9gXtTOrriYN6G7xwoL/F2+Bp5hTr2xuXG0d+tfnG/cvN85qNy42jV4NROnhd+/O5JXp5zxiPPb2LLRPhvWMXjz29i5deGQMgAk5fdByvW348SxceXQu43v0nVZrDcN9cZm9DGDacYGk1am08wdPf00NPj8EozRcG+iHITP73hV+yZUdDeD+9iyef+wVZn4lYcFQfq5cu5O3nL2P10oWsXrqQs05ewDEDvd0tXlKxDPQ2do/uZWvDqHvL07t4bMdOdu4e29fmtBOPZfWShfzuG5axeukCVi9dyPJXH+O0gaRZZaDXZSZP79xdD+79Af7Es79g4oqxYwd6OXvJAt527in7R91LFvCqo/w2Suq+eZtEY3vH+dZDO/jx9hfrI++dvPDy6L79y199DKuXLuR3Xn8Ka5Yu4OwlCzn1V451TlrSEWteBvozO3dz3a33c88TP+fo/h7OWrKQy89ZwtlLaqPus5cuYOHR/d0uU5IOyrwL9B/+5Dmuu/V+XnpllL9/57n83nnL6HXULakA8ybQx8eTz/znT/jkv21l5aLjuOW9F3LWkgXdLkuSOmZeBPrzv9jD9bc/wF1bR3jbuafwt29/nScyJRWn+FR7YPsLfOiWHzGy6xU+tva1XHXRaV5OKKlIxQZ6ZvKFHzzJX2/ewskLj+ZrH3gjr1/e+b8/LElHiiIDfdfuUW74+kN866EdXLr6JD75zjdw/LFetSKpbMUF+pYdO/ngLT/iZz9/mRsuP5trfuMMrx2XNC8UFei3D23nL+94mOOP6efL772QC884sdslSdKsKSLQf7lnLzd+42G+et8wv/6rJ/KP685j8YKjul2WJM2qOR/oj4+8xAdv+RGPPb2L637rNfzJpWf6QSFJ89KcDvRvPbiDP/v6g/T3Bje/59e4+KyTul2SJHXNnAz0PWPj/M3mLdz8gyc579QT2PD753PKCcd0uyxJ6qo5F+jPvfQKV39hiAe2v8Afvel0brj8bAb6erpdliR13ZwL9DseeIoHtr/AP60/j7ede0q3y5GkI8acG9qO1W+qfMlq58slqdGcC3RJUmsGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFaJSoEfEZRGxNSK2RcQNLfafGhF3RcT9EfFgRFzR+VIlSdNpG+gR0QtsAC4H1gDrI2JNU7O/AG7PzPOAdcA/d7pQSdL0qozQLwC2ZebjmbkHuA1Y29QmgYX15eOBpzpXoiSpiiqBvgzY3rA+XN/W6KPAVRExDGwGrmt1oIi4JiKGImJoZGTkEMqVJE2lSqC3ukFnNq2vB27OzOXAFcCXIuKAY2fmxswczMzBxYsXH3y1kqQpVQn0YWBFw/pyDpxSuRq4HSAzfwgcDSzqRIGSpGqqBPq9wKqIOD0iBqid9NzU1OZnwCUAEbGaWqA7pyJJs6htoGfmGHAtcCewhdrVLI9ExE0RcWW92YeB90XEj4FbgXdnZvO0jCRpBlW6p2hmbqZ2srNx240Ny48Cb+psaZKkg+EnRSWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhKgV6RFwWEVsjYltE3DBFm3dFxKMR8UhEfLmzZUqS2ulr1yAieoENwG8Dw8C9EbEpMx9taLMK+HPgTZn5fEScNFMFS5JaqzJCvwDYlpmPZ+Ye4DZgbVOb9wEbMvN5gMx8prNlSpLaqRLoy4DtDevD9W2NzgTOjIjvR8TdEXFZqwNFxDURMRQRQyMjI4dWsSSppSqBHi22ZdN6H7AKuBhYD/xLRJxwwIMyN2bmYGYOLl68+GBrlSRNo0qgDwMrGtaXA0+1aPONzBzNzCeArdQCXpI0S6oE+r3Aqog4PSIGgHXApqY2dwBvAYiIRdSmYB7vZKGSpOm1DfTMHAOuBe4EtgC3Z+YjEXFTRFxZb3Yn8FxEPArcBfxpZj43U0VLkg7U9rJFgMzcDGxu2nZjw3IC19e/JEld4CdFJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqRKVAj4jLImJrRGyLiBumafeOiMiIGOxciZKkKtoGekT0AhuAy4E1wPqIWNOi3QLgj4F7Ol2kJKm9KiP0C4Btmfl4Zu4BbgPWtmj3MeDjwO4O1idJqqhKoC8DtjesD9e37RMR5wErMvOb0x0oIq6JiKGIGBoZGTnoYiVJU6sS6NFiW+7bGdEDfAr4cLsDZebGzBzMzMHFixdXr1KS1FaVQB8GVjSsLweealhfAJwDfDcingQuAjZ5YlSSZleVQL8XWBURp0fEALAO2DSxMzNfzMxFmbkyM1cCdwNXZubQjFQsSWqpbaBn5hhwLXAnsAW4PTMfiYibIuLKmS5QklRNX5VGmbkZ2Ny07cYp2l58+GVJkg6WnxSVpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhagU6BFxWURsjYhtEXFDi/3XR8SjEfFgRHwnIk7rfKmSpOm0DfSI6AU2AJcDa4D1EbGmqdn9wGBmvh74GvDxThcqSZpelRH6BcC2zHw8M/cAtwFrGxtk5l2Z+XJ99W5geWfLlCS1UyXQlwHbG9aH69umcjXw7VY7IuKaiBiKiKGRkZHqVUqS2qoS6NFiW7ZsGHEVMAh8otX+zNyYmYOZObh48eLqVUqS2uqr0GYYWNGwvhx4qrlRRFwKfAR4c2a+0pnyJElVVRmh3wusiojTI2IAWAdsamwQEecBnwOuzMxnOl+mJKmdtoGemWPAtcCdwBbg9sx8JCJuiogr680+AbwK+GpEPBARm6Y4nCRphlSZciEzNwObm7bd2LB8aYfrkiQdJD8pKkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSISoFekRcFhFbI2JbRNzQYv9REfGV+v57ImJlpwuVJE2vbaBHRC+wAbgcWAOsj4g1Tc2uBp7PzNcAnwL+rtOFSpKmV2WEfgGwLTMfz8w9wG3A2qY2a4Ev1Je/BlwSEdG5MiVJ7VQJ9GXA9ob14fq2lm0ycwx4ETix+UARcU1EDEXE0MjIyCEVfPqi47jidUvo8f8LSZqkr0KbVsmZh9CGzNwIbAQYHBw8YH8Vb33tEt762iWH8lBJKlqVEfowsKJhfTnw1FRtIqIPOB74eScKlCRVUyXQ7wVWRcTpETEArAM2NbXZBPxhffkdwH9k5iGNwCVJh6btlEtmjkXEtcCdQC/w+cx8JCJuAoYycxPwr8CXImIbtZH5upksWpJ0oCpz6GTmZmBz07YbG5Z3A+/sbGmSpIPhJ0UlqRAGuiQVwkCXpEIY6JJUiOjW1YURMQL89BAfvgh4toPlzAX2eX6wz/PD4fT5tMxc3GpH1wL9cETEUGYOdruO2WSf5wf7PD/MVJ+dcpGkQhjoklSIuRroG7tdQBfY5/nBPs8PM9LnOTmHLkk60FwdoUuSmhjoklSIIzrQ5+PNqSv0+fqIeDQiHoyI70TEad2os5Pa9bmh3TsiIiNizl/iVqXPEfGu+mv9SER8ebZr7LQKP9unRsRdEXF//ef7im7U2SkR8fmIeCYiHp5if0TEp+vfjwcj4vzDftLMPCK/qP2p3p8AZwADwI+BNU1tPgh8tr68DvhKt+uehT6/BTi2vvyB+dDnersFwPeAu4HBbtc9C6/zKuB+4NX19ZO6Xfcs9Hkj8IH68hrgyW7XfZh9/k3gfODhKfZfAXyb2h3fLgLuOdznPJJH6PPx5tRt+5yZd2Xmy/XVu6ndQWouq/I6A3wM+DiwezaLmyFV+vw+YENmPg+Qmc/Mco2dVqXPCSysLx/PgXdGm1My83tMf+e2tcAXs+Zu4ISIWHo4z3kkB3rHbk49h1Tpc6Orqf0PP5e17XNEnAesyMxvzmZhM6jK63wmcGZEfD8i7o6Iy2atuplRpc8fBa6KiGFq91+4bnZK65qD/X1vq9INLrqkYzennkMq9ycirgIGgTfPaEUzb9o+R0QP8Cng3bNV0Cyo8jr3UZt2uZjau7D/iohzMvOFGa5tplTp83rg5sz8ZES8kdpd0M7JzPGZL68rOp5fR/IIfT7enLpKn4mIS4GPAFdm5iuzVNtMadfnBcA5wHcj4klqc42b5viJ0ao/29/IzNHMfALYSi3g56oqfb4auB0gM38IHE3tj1iVqtLv+8E4kgN9Pt6cum2f69MPn6MW5nN9XhXa9DkzX8zMRZm5MjNXUjtvcGVmDnWn3I6o8rN9B7UT4ETEImpTMI/PapWdVaXPPwMuAYiI1dQCfWRWq5xdm4A/qF/tchHwYmbuOKwjdvtMcJuzxFcA/0Pt7PhH6ttuovYLDbUX/KvANuC/gTO6XfMs9Pnfgf8DHqh/bep2zTPd56a232WOX+VS8XUO4B+AR4GHgHXdrnkW+rwG+D61K2AeAN7a7ZoPs7+3AjuAUWqj8auB9wPvb3iNN9S/Hw914ufaj/5LUiGO5CkXSdJBMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIf4fg8vdc1mtOvkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fpr,tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9784507042253521"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test,m_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## kfold\n",
    "## s folds---> in each and every folfd-->create a part of test data and remaining will be of training data\n",
    "from sklearn.model_selection import KFold\n",
    "kfold=KFold(n_splits=5)\n",
    "kfold.get_n_splits(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9122807017543859, 0.9122807017543859, 0.9649122807017544, 0.9473684210526315, 0.9469026548672567]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model_knn=KNeighborsClassifier(n_neighbors=6,metric='euclidean')\n",
    "# model will built for 5 times-->for loop\n",
    "# some set of indices will be in tesst data andthe remaining  set of indices will\n",
    "## be in trqaining data\n",
    "# IN each and evvery fold ,it is spliting training data and testing data\n",
    "# kfold will return the indices of the records which are splitted , to acess the \n",
    "# records in that indicess we are using iloc\n",
    "score=[]\n",
    "for train_index,test_index in kfold.split(X,y):\n",
    "    X_train,X_test=X.iloc[train_index],X.iloc[test_index]\n",
    "    y_train,y_test=y.iloc[train_index],y.iloc[test_index]\n",
    "    \n",
    "    # pass the X_train ,y_train into the knn algorithm\n",
    "    model_knn.fit(X_train,y_train)\n",
    "    \n",
    "    # predict the model on test data(X_test,y_test)\n",
    "    y_pred_test=model_knn.predict(X_test)\n",
    "    \n",
    "    # accuracy score of predicted values(y_pred_test) and A.V(y_test)\n",
    "    accuracy=accuracy_score(y_test,y_pred_test)\n",
    "    score.append(accuracy)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    " # http://tiny.cc/NaiveBayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
